use crate::{
    Number, Text, TextToken, Token2, Word,
    options::{IntoTokenizer, TokenizerOptions, TokenizerParams},
};

use std::collections::BTreeMap;

/*2 –æ–∫—Ç—è–±—Ä—è: 20.000 —Ä—É–±–ª–µ–π, —Å 3 –æ–∫—Ç—è–±—Ä—è - 22.000 —Ä—É–±–ª–µ–π, –≤ –¥–µ–Ω—å —Å–µ–º–∏–Ω–∞—Ä–∞ - 25.000 —Ä—É–±–ª–µ–π.


Œú–∞—Ç–∫–∞–ø–∏—Ç–∞–ª –≤—ã—Ä–∞—Ç–µ—Ç c 1 —Ñe–≤pa–ª—è 2026 –≥Œø–¥a
‚ñ™Ô∏èÔ∏è 974.000‚ÇΩ –Ωa –≤—ÇŒøpŒø–≥Œø pe–±—ë–ΩŒ∫a, ec–ª–∏ ce–º—å—è –Ωe –øŒø–ª—É—áa–ªa –≤—ã–ø–ªa—Ç –Ωa –øep–≤e–Ω—Üa
‚ñ™Ô∏è737.000‚ÇΩ ‚Äî –Ωa –øep–≤Œø–≥Œø
‚ñ™Ô∏èÔ∏è Œï–¥–∏–ΩŒø–≤pe–ºe–Ω–ΩŒøe –øŒøcŒø–±–∏e –øp–∏ pŒø–∂–¥e–Ω–∏–∏ pe–±—ë–ΩŒ∫a —É–≤e–ª–∏—á–∏—Çc—è –¥Œø 28.773‚ÇΩ.
Ô∏èüìçŒúaŒ∫c–∏–ºa–ª—å–Ωa—è c—É–º–ºa –øŒøcŒø–±–∏—è –øŒø –±epe–ºe–Ω–ΩŒøc—Ç–∏ –∏ pŒø–¥a–º –≤—ãpac—Çe—Ç –¥Œø 955.000‚ÇΩ
Ô∏èüìçŒ†ŒøcŒø–±–∏e –øŒø —ÉxŒø–¥—É –∑a pe–±—ë–ΩŒ∫Œø–º –¥Œø 1,5 –ªe—Ç –¥–ª—è pa–±Œø—Ça—é—â–∏x –≥pa–∂–¥a–Ω ‚Äî –¥Œø 83.000‚ÇΩ –≤ –ºec—è—Ü.

1.950.000‚ÇΩ —Ç–æ—Ä–≥
Œú–∞—Ä–∫–∞:V–ælksw–∞g–µn
Œú–æ–¥–µ–ª—å: Jett–∞
Œì–æ–¥ –≤—ã–ø—É—Å–∫–∞: 01/2020
–î–≤–∏–≥–∞—Ç–µ–ª—å: 1.4 –ëe–Ω–∑–∏–Ω
Œ†—Ä–æ–±e–≥: 104—Ç –∫–º

—Å—Ç–æ–∏–º–æ—Å—Ç—å –≤–µ–∑–¥–µ—Ö–æ–¥–æ–≤ –±–∞–∑–æ–≤–æ–π –∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –æ—Ç 2.080.000 —Ä—É–±–ª–µ–π –∏ –≤—ã—à–µ.

Œï–¥–∏–ΩŒø–≤pe–ºe–Ω–ΩŒøe –øŒøcŒø–±–∏e –øp–∏ pŒø–∂–¥e–Ω–∏–∏ pe–±—ë–ΩŒ∫a —É–≤e–ª–∏—á–∏—Çc—è –¥Œø 28.773‚ÇΩ.
 */

struct WordChecker<'s> {
    words: BTreeMap<&'s str, (Token2, usize)>,
}
impl<'s> WordChecker<'s> {
    // be careful with the same words used several time
    fn new<'q>(words: &[(&'q str, Token2)]) -> WordChecker<'q> {
        WordChecker {
            words: words.iter().cloned().map(|(s, t)| (s, (t, 0))).collect(),
        }
    }

    fn check(&mut self, text: &Text, token: &TextToken) {
        let s = text.token_text(&token);
        if let Some((rtok, cnt)) = self.words.get_mut(s) {
            *cnt += 1;
            assert_eq!(rtok.clone(), token.token);
        }
    }
    fn check_count(&self) {
        for (s, (t, cnt)) in &self.words {
            if *cnt == 0 {
                panic!("Missed word '{}': {:?}", s, t);
            }
        }
    }
}

#[test]
fn test_ru_01() {
    let txt =
        "2 –æ–∫—Ç—è–±—Ä—è: 20.000 —Ä—É–±–ª–µ–π, —Å 3 –æ–∫—Ç—è–±—Ä—è - 22.000 —Ä—É–±–ª–µ–π, –≤ –¥–µ–Ω—å —Å–µ–º–∏–Ω–∞—Ä–∞ - 25.000 —Ä—É–±–ª–µ–π.";

    let mut checker = WordChecker::new(&[
        (
            "20.000",
            Token2::Word(Word::Number(Number::Integer(20_000))),
        ),
        (
            "22.000",
            Token2::Word(Word::Number(Number::Integer(22_000))),
        ),
        (
            "25.000",
            Token2::Word(Word::Number(Number::Integer(25_000))),
        ),
    ]);

    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1()) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}

#[test]
fn test_ru_02() {
    let txt = "1.950.000‚ÇΩ —Ç–æ—Ä–≥
Œú–∞—Ä–∫–∞:V–ælksw–∞g–µn
Œú–æ–¥–µ–ª—å: Jett–∞
Œì–æ–¥ –≤—ã–ø—É—Å–∫–∞: 01/2020
–î–≤–∏–≥–∞—Ç–µ–ª—å: 1.4 –ëe–Ω–∑–∏–Ω
Œ†—Ä–æ–±e–≥: 104—Ç –∫–º";

    let mut checker = WordChecker::new(&[
        (
            "1.950.000",
            Token2::Word(Word::Number(Number::Integer(1_950_000))),
        ),
        ("1.4", Token2::Word(Word::Number(Number::Float(1.4)))),
    ]);

    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1()) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}

#[test]
#[rustfmt::skip]
fn custom_numbers() {
    let txt = "115,7 123,398,398 2,123.45 0,05%";

    let mut checker = WordChecker::new(&[
        ("115,7", Token2::Word(Word::Number(Number::Float(115.7)))),
        ("123,398,398", Token2::Word(Word::Number(Number::Integer(123398398)))),
        ("2,123.45", Token2::Word(Word::Number(Number::Float(2123.45)))),
        ("0,05", Token2::Word(Word::Number(Number::Float(0.05)))),
    ]);

    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1()) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}

#[test]
#[rustfmt::skip]
fn custom_numbers_ftoi() {
    let txt = "1.1 10.0000";

    let mut checker = WordChecker::new(&[
        ("1.1", Token2::Word(Word::Number(Number::Float(1.1)))),
        ("10.0000", Token2::Word(Word::Number(Number::Integer(10)))),
    ]);

    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1()) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}

#[test]
#[rustfmt::skip]
fn custom_numbers_en_1() {
    let txt = "1.1 10,000";
    
    let mut checker = WordChecker::new(&[
        ("1.1", Token2::Word(Word::Number(Number::Float(1.1)))),
        ("10,000", Token2::Word(Word::Number(Number::Integer(10000)))),
    ]);
    
    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1()) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}

#[test]
#[rustfmt::skip]
fn custom_numbers_en_2() {
    let txt = "1,000.1 10,000";

    let mut checker = WordChecker::new(&[
        ("1,000.1", Token2::Word(Word::Number(Number::Float(1000.1)))),
        ("10,000", Token2::Word(Word::Number(Number::Integer(10000)))),
    ]);
    
    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1()) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}

#[test]
#[rustfmt::skip]
fn custom_numbers_ru_1() {
    let txt = "1.1 10,001";

    let mut checker = WordChecker::new(&[
        ("1.1", Token2::Word(Word::Number(Number::Float(1.1)))),
        ("10,001", Token2::Word(Word::Number(Number::Integer(10001)))),
    ]);
    
    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1().add_option(TokenizerOptions::NumberUnknownComaAsDot)) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}

#[test]
#[rustfmt::skip]
fn custom_numbers_ru_2() {
    let txt = "1,1 10,001";

    let mut checker = WordChecker::new(&[
        ("1,1", Token2::Word(Word::Number(Number::Float(1.1)))),
        ("10,001", Token2::Word(Word::Number(Number::Integer(10001)))),
    ]);
    
    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1()) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}

#[test]
#[rustfmt::skip]
fn custom_numbers_ru_3() {
    let txt = "10000,1 10,001";

    let mut checker = WordChecker::new(&[
        ("10000,1", Token2::Word(Word::Number(Number::Float(10000.1)))),
        ("10,001", Token2::Word(Word::Number(Number::Integer(10001)))),
    ]);
    
    let text = Text::try_from(txt).unwrap();
    for tok in text.into_tokenizer(TokenizerParams::v1()) {
        println!("[ {} ] {:?}", text.token_text(&tok), tok);
        checker.check(&text, &tok);
    }
    checker.check_count();
}
