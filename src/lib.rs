use std::sync::Arc;
use text_parsing::{Breaker, IntoSource, Local, Snip, Source, SourceEvent};

mod emoji;
pub use emoji::EMOJIMAP;

mod breakers;
pub use breakers::{SentenceBreaker, UnicodeSentenceBreaker};

mod wordbreaker;

mod options;
pub use options::{IntoTokenizer, TokenizerOptions, TokenizerParams};

mod tokens;
pub use tokens::Tokens;

mod text_tokens;
use text_tokens::InnerBound;
pub use text_tokens::TextTokens;

#[derive(Debug)]
pub enum Error {
    TextParser(text_parsing::Error),
}

const EPS: f64 = 1e-10;

#[derive(Debug, Clone, Copy, PartialEq, PartialOrd)]
pub enum Number {
    Integer(i64),
    Float(f64),
}
impl Number {
    pub fn as_f64(&self) -> f64 {
        match self {
            Number::Integer(i) => *i as f64,
            Number::Float(f) => *f,
        }
    }
}
impl Ord for Number {
    fn cmp(&self, other: &Number) -> std::cmp::Ordering {
        let s = self.as_f64();
        let o = other.as_f64();
        let d = s - o;
        match d.abs() < EPS {
            true => std::cmp::Ordering::Equal,
            false => {
                if d > 0.0 {
                    return std::cmp::Ordering::Greater;
                }
                if d < 0.0 {
                    return std::cmp::Ordering::Less;
                }
                std::cmp::Ordering::Equal
            }
        }
    }
}
impl Eq for Number {}

#[derive(Debug, Clone, Copy, Eq, PartialEq, Ord, PartialOrd)]
pub enum Separator {
    Space,
    Tab,
    Newline,
    Char(char),
}

#[derive(Debug, Clone, Copy, Eq, PartialEq, Ord, PartialOrd)]
pub enum Formatter {
    Char(char),
    Joiner, // u{200d}
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Ord, PartialOrd)]
pub enum Special {
    Punctuation(char),
    Symbol(char),
    Separator(Separator),
}

#[cfg(feature = "strings")]
#[derive(Debug, Clone, PartialEq, PartialOrd, Eq, Ord)]
pub enum Word {
    Word(String),
    StrangeWord(String),
    Numerical(Numerical),
    Number(Number),
    Emoji(&'static str),
}

#[cfg(feature = "strings")]
#[derive(Debug, Clone, Eq, PartialEq, Ord, PartialOrd)]
pub enum Numerical {
    //Date(String),
    //Ip(String),
    //Countable(String),
    DotSeparated(String),
    Measures(String),
    Alphanumeric(String),
}

#[cfg(feature = "strings")]
#[derive(Debug, Clone, PartialEq, PartialOrd, Eq, Ord)]
pub enum Struct {
    Hashtag(String),
    Mention(String),
    //Url(String),
}

#[cfg(feature = "strings")]
#[derive(Debug, Clone, PartialEq, PartialOrd, Eq, Ord)]
pub enum Unicode {
    String(String),
    Formatter(Formatter),
}

#[cfg(not(feature = "strings"))]
#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord)]
pub enum Word {
    Word,
    StrangeWord,
    Numerical(Numerical),
    Number(Number),
    Emoji(&'static str),
}

#[cfg(not(feature = "strings"))]
#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord)]
pub enum Numerical {
    //Date,
    //Ip,
    //Countable,
    DotSeparated,
    Measures,
    Alphanumeric,
}

#[cfg(not(feature = "strings"))]
#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord)]
pub enum Struct {
    Hashtag,
    Mention,
    //Url,
}

#[cfg(not(feature = "strings"))]
#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord)]
pub enum Unicode {
    String,
    Formatter(Formatter),
}

#[cfg(feature = "strings")]
#[derive(Debug, Clone, PartialEq, PartialOrd, Eq, Ord)]
pub enum Token {
    Word(Word),
    Struct(Struct),
    Special(Special),
    Unicode(Unicode),
}

#[cfg(not(feature = "strings"))]
#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord)]
pub enum Token {
    Word(Word),
    Struct(Struct),
    Special(Special),
    Unicode(Unicode),
}

/*pub trait IntoTokens<T> {
    type IntoTokens: IntoTokenizer<IntoTokens = T>;
}

impl<'s> IntoTokenSource<Token2> for &'s str {
    type IntoTokens = TextStr<'s>;

    fn (self) -> Result<TextStr<'s>,Error> {
        TextStr::new(self)
    }

}*/

#[derive(Debug)]
pub struct TextStr<'s> {
    buffer: &'s str,
    originals: Vec<Local<()>>,
    breakers: Vec<InnerBound>,
}
impl<'s> TextStr<'s> {
    pub fn new<'a>(s: &'a str) -> Result<TextStr<'a>, Error> {
        let text = inner_new(s.into_source(), false)?;
        Ok(TextStr {
            buffer: s,
            originals: text.originals,
            breakers: text.breakers,
        })
    }
}

fn inner_new<S: Source>(mut source: S, with_buffer: bool) -> Result<Text, Error> {
    let mut buffer = String::new();
    let mut originals = Vec::new();
    let mut breakers = Vec::new();

    while let Some(local_se) = source.next_char().map_err(Error::TextParser)? {
        let (local, se) = local_se.into_inner();
        let c = match se {
            SourceEvent::Char(c) => match c {
                '\u{0060}' => '\u{0027}',
                _ => c,
            },
            SourceEvent::Breaker(b) => {
                let (c, opt_b) = match b {
                    Breaker::None => continue,
                    Breaker::Space => (' ', None),
                    Breaker::Line => ('\n', None),
                    Breaker::Word => ('\u{200B}', Some(b)), // zero width space
                    Breaker::Sentence | Breaker::Paragraph | Breaker::Section => ('\n', Some(b)),
                };
                if let Some(b) = opt_b {
                    let br = InnerBound {
                        bytes: Snip {
                            offset: buffer.len(),
                            length: c.len_utf8(),
                        },
                        chars: Snip {
                            offset: originals.len(),
                            length: 1,
                        },
                        breaker: b,
                        original: Some(local),
                    };
                    //println!("BR: {:?}",br);
                    breakers.push(br);
                }
                c
            }
        };
        if with_buffer {
            buffer.push(c);
        }
        originals.push(local);
    }
    Ok(Text {
        buffer: Arc::new(buffer),
        originals,
        breakers,
    })
}

#[derive(Debug)]
pub struct Text {
    buffer: Arc<String>,
    originals: Vec<Local<()>>,
    breakers: Vec<InnerBound>,
}
impl Text {
    pub fn new<S: Source>(source: S) -> Result<Text, Error> {
        inner_new(source, true)
    }
    pub fn token_text<'s>(&'s self, token: &TextToken) -> &'s str {
        let Snip {
            offset: begin,
            length: len,
        } = token.locality.bytes();
        let end = begin + len;
        &self.buffer[begin..end]
    }
    pub fn text(&self) -> &str {
        self.buffer.as_ref()
    }
    pub fn original_locality(&self, idx: usize) -> Option<Local<()>> {
        self.originals.get(idx).copied()
    }
    pub fn originals(&self) -> &Vec<Local<()>> {
        &self.originals
    }
    pub fn shared_text(&self) -> Arc<String> {
        self.buffer.clone()
    }
}

impl TryFrom<String> for Text {
    type Error = Error;

    fn try_from(s: String) -> Result<Text, Error> {
        let mut text = inner_new((&s).into_source(), false)?;
        text.buffer = Arc::new(s);
        Ok(text)
    }
}

impl TryFrom<&str> for Text {
    type Error = Error;

    fn try_from(s: &str) -> Result<Text, Error> {
        Text::new(s.into_source())
    }
}

#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord)]
pub enum Bound {
    Sentence,
    Paragraph,
    Section,
}

#[cfg(feature = "strings")]
#[derive(Debug, Clone, PartialEq, PartialOrd, Eq, Ord)]
pub struct TextToken {
    locality: Local<()>,
    original: Option<Local<()>>,
    pub token: Token2,
}

#[cfg(not(feature = "strings"))]
#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord)]
pub struct TextToken {
    locality: Local<()>,
    original: Option<Local<()>>,
    pub token: Token2,
}

#[cfg(test)]
impl TextToken {
    fn into_original_token_1(self) -> Option<Local<Token>> {
        match self.original {
            Some(original) => self.token.into_token().map(|t| original.local(t)),
            None => None,
        }
    }
}

impl TextToken {
    pub fn local(&self) -> Local<()> {
        self.locality
    }
    pub fn original(&self) -> Option<Local<()>> {
        self.original
    }
    pub fn into_position(mut self) -> TextToken {
        self.locality = self.locality.into_position();
        self.original = self.original.map(|or| or.into_position());
        self
    }
    pub fn try_as_token(&self) -> Result<Token, Bound> {
        self.token.try_as_token()
    }
    pub fn as_original_token(&self) -> Option<Local<&Token2>> {
        self.original.map(|original| original.local(&self.token))
    }
    pub fn into_original_token(self) -> Option<Local<Token2>> {
        self.original.map(|original| original.local(self.token))
    }
    pub fn original_str<'s>(&self, original: &'s str) -> Result<&'s str, OriginalError> {
        match self.original {
            Some(local) => {
                let Snip {
                    offset: begin,
                    length: len,
                } = local.bytes();
                let end = begin + len;
                match original.get(begin..end) {
                    Some(s) => Ok(s),
                    None => Err(OriginalError::InvalidSnip),
                }
            }
            None => Err(OriginalError::NoOriginal),
        }
    }

    pub fn test_token(lt: Local<Token2>) -> TextToken {
        let (local, token) = lt.into_inner();
        TextToken {
            locality: local,
            original: Some(local.local(())),
            token,
        }
    }
    pub fn test_new(token: Token2, local: Local<()>, original: Option<Local<()>>) -> TextToken {
        TextToken {
            locality: local,
            original,
            token,
        }
    }
}

/*pub trait TokenExt: Iterator<Item = TextToken> + Sized {
    fn merge_separators(self) -> Merger<Self>;
}

impl<T> TokenExt for T where T: Iterator<Item = TextToken> {
    fn merge_separators(self) -> Merger<Self> {
        Merger {
            tokens: self,
        }
    }
}

pub struct Merger<T>
where T: Iterator<Item = TextToken>
{
    tokens: T,
}
impl<T> Iterator for Merger<T>
where T: Iterator<Item = TextToken>
{
    type Item = TextToken;
    fn next(&mut self) -> Option<Self::Item> {
        self.tokens.next()
    }
}*/

#[derive(Debug)]
pub enum OriginalError {
    NoOriginal,
    InvalidSnip,
}

/*#[derive(Debug,Clone,PartialEq)]
pub enum ExtToken {
    Token(Local<Token>),
    Breaker(Local<Bound>),
    Bound(Bound),
}*/

#[cfg(feature = "strings")]
#[derive(Debug, Clone, PartialEq, PartialOrd, Eq, Ord)]
pub enum Token2 {
    Word(Word),
    Struct(Struct),
    Special(Special),
    Unicode(Unicode),

    Bound(Bound),
}
#[cfg(not(feature = "strings"))]
#[derive(Debug, Clone, Copy, PartialEq, PartialOrd, Eq, Ord)]
pub enum Token2 {
    Word(Word),
    Struct(Struct),
    Special(Special),
    Unicode(Unicode),

    Bound(Bound),
}
impl From<Token> for Token2 {
    fn from(t: Token) -> Token2 {
        match t {
            Token::Word(w) => Token2::Word(w),
            Token::Struct(s) => Token2::Struct(s),
            Token::Special(s) => Token2::Special(s),
            Token::Unicode(u) => Token2::Unicode(u),
        }
    }
}
impl Token2 {
    #[cfg(not(feature = "strings"))]
    fn try_as_token(&self) -> Result<Token, Bound> {
        (*self).try_into_token()
    }

    #[cfg(feature = "strings")]
    fn try_as_token(&self) -> Result<Token, Bound> {
        self.clone().try_into_token()
    }

    fn try_into_token(self) -> Result<Token, Bound> {
        match self {
            Token2::Word(w) => Ok(Token::Word(w)),
            Token2::Struct(s) => Ok(Token::Struct(s)),
            Token2::Special(s) => Ok(Token::Special(s)),
            Token2::Unicode(u) => Ok(Token::Unicode(u)),
            Token2::Bound(b) => Err(b),
        }
    }
}
#[cfg(test)]
impl Token2 {
    fn into_token(self) -> Option<Token> {
        match self {
            Token2::Word(w) => Some(Token::Word(w)),
            Token2::Struct(s) => Some(Token::Struct(s)),
            Token2::Special(s) => Some(Token::Special(s)),
            Token2::Unicode(u) => Some(Token::Unicode(u)),
            Token2::Bound(_) => None,
        }
    }
}

#[cfg(test)]
mod test_v0_5 {
    use super::*;
    use text_parsing::{entities, tagger, IntoPipeParser, IntoSource, ParserExt, SourceExt};

    //#[test]
    fn basic() {
        /*let uws = "Oxana Putan shared the quick (\"brown\") fox can't jump 32.3 feet, right?4pda etc. qeq U.S.A  asd\n\n\nBrr, it's 29.3¬∞F!\n –†—É—Å—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #36.6 –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –ø–æ —é–Ω–∏–∫–æ–¥-—Å–ª–æ–≤–∞–º...\nüá∑üá∫ üá∏üáπ\nüë±üèøüë∂üèΩüë®üèΩ\n+Done! –ì–æ—Ç–æ–≤–æ";

        /*let result = vec![
            PositionalToken { source: uws, offset: 0, length: 7, token: Token::Word("l'oreal".to_string()) },
            PositionalToken { source: uws, offset: 7, length: 1, token: Token::Punctuation(";".to_string()) },
            PositionalToken { source: uws, offset: 8, length: 1, token: Token::Separator(Separator::Space) },
            PositionalToken { source: uws, offset: 9, length: 7, token: Token::Word("l'oreal".to_string()) },
        ];*/
        let text = Text::new({
            uws.into_source()
                .into_separator()
                .merge_separators()
        }).unwrap();*/

        let uws = "<p>Oxana Putan shared the quick (\"brown\") fox can't jump 32.3 feet, right? 4pda etc.</p><p> qeq U.S.A  asd\n\n\nBrr, it's 29.3¬∞F!\n –†—É—Å—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #36.6 –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –ø–æ —é–Ω–∏–∫–æ–¥-—Å–ª–æ–≤–∞–º...\nüá∑üá∫ üá∏üáπ\nüë±üèøüë∂üèΩüë®üèΩ\n+Done! –ì–æ—Ç–æ–≤–æ</p>";
        let text = Text::new({
            uws.into_source()
                .pipe(tagger::Builder::new().create().into_breaker())
                .pipe(entities::Builder::new().create().into_piped())
                .into_separator()
        })
        .unwrap();
        let lib_res = text
            .into_tokenizer({
                TokenizerParams::default()
                    .add_option(TokenizerOptions::SplitDot)
                    .add_option(TokenizerOptions::SplitUnderscore)
                    .add_option(TokenizerOptions::SplitColon)
                    .with_default_sentences()
            })
            .collect::<Vec<_>>();

        for tok in lib_res {
            println!(
                "C{:?}, B{:?}, {:?} -> {:?}",
                tok.original.map(|loc| loc.chars()),
                tok.original.map(|loc| loc.bytes()),
                tok.token,
                tok.original_str(uws)
            );
        }

        panic!()
    }
}

#[cfg(test)]
#[cfg(feature = "strings")]
mod test {
    use super::*;
    use text_parsing::{
        entities, tagger, IntoPipeParser, IntoSource, Localize, ParserExt, SourceExt,
    };

    /*
    #[allow(dead_code)]
    fn print_pt(tok: &PositionalToken) -> String {
        let mut r = match &tok.token {
            Token::BBCode{ left, right } => {
                let left = print_pts(left);
                let right = print_pts(right);
                format!("PositionalToken {{ offset: {}, length: {}, token: Token::BBCode {{ left: vec![\n{}], right: vec![\n{}] }} }},",tok.offset,tok.length,left,right)
            },
            _ => format!("PositionalToken {{ offset: {}, length: {}, token: Token::{:?} }},",tok.offset,tok.length,tok.token),
        };
        r = r.replace("\")","\".to_string())");
        r
    }
    #[allow(dead_code)]
    fn print_pts(lib_res: &Vec<PositionalToken>) -> String {
        let mut r = String::new();
        for tok in lib_res {
            r += &print_pt(&tok);
            r += "\n";
        }
        r
    }
    #[allow(dead_code)]
    fn print_result(lib_res: &Vec<PositionalToken>) {
        let mut r = print_pts(lib_res);
        r = r.replace("Separator(","Separator(Separator::");
        r = r.replace("UnicodeFormatter(","UnicodeFormatter(Formatter::");
        r = r.replace("Number(","Number(Number::");
        r = r.replace("Numerical(","Numerical(Numerical::");
        println!("{}",r);
    }

    #[allow(dead_code)]
    fn print_ct(tok: &CharToken) -> String {
        let mut r = format!("CharToken {{ byte_offset: {}, byte_length: {}, char_offset: {}, char_length: {}, token: Token::{:?} }},",tok.byte_offset,tok.byte_length,tok.char_offset,tok.char_length,tok.token);
        r = r.replace("\")","\".to_string())");
        r
    }

    #[allow(dead_code)]
    fn print_cts(lib_res: &Vec<CharToken>) -> String {
        let mut r = String::new();
        for tok in lib_res {
            r += &print_ct(&tok);
            r += "\n";
        }
        r
    }

    #[allow(dead_code)]
    fn print_cresult(lib_res: &Vec<CharToken>) {
        let mut r = print_cts(lib_res);
        r = r.replace("Separator(","Separator(Separator::");
        r = r.replace("UnicodeFormatter(","UnicodeFormatter(Formatter::");
        r = r.replace("Number(","Number(Number::");
        r = r.replace("Numerical(","Numerical(Numerical::");
        println!("{}",r);
    }*/

    #[derive(Debug, Clone)]
    struct CharToken {
        byte_offset: usize,
        byte_length: usize,
        char_offset: usize,
        char_length: usize,
        token: Token,
    }
    impl Into<Local<Token>> for CharToken {
        fn into(self) -> Local<Token> {
            self.token.localize(
                Snip {
                    offset: self.char_offset,
                    length: self.char_length,
                },
                Snip {
                    offset: self.byte_offset,
                    length: self.byte_length,
                },
            )
        }
    }

    #[derive(Debug, Clone)]
    struct PositionalToken {
        source: &'static str,
        offset: usize,
        length: usize,
        token: Token,
    }
    impl Into<Local<Token>> for PositionalToken {
        fn into(self) -> Local<Token> {
            self.token.localize(
                Snip {
                    offset: self.source[..self.offset].chars().count(),
                    length: self.source[self.offset..self.offset + self.length]
                        .chars()
                        .count(),
                },
                Snip {
                    offset: self.offset,
                    length: self.length,
                },
            )
        }
    }

    fn check_results(result: &Vec<PositionalToken>, lib_res: &Vec<Local<Token>>, _uws: &str) {
        assert_eq!(result.len(), lib_res.len());
        for i in 0..result.len() {
            let res: Local<Token> = result[i].clone().into();
            assert_eq!(res, lib_res[i]);
        }
    }

    fn check_cresults(result: &Vec<CharToken>, lib_res: &Vec<Local<Token>>, _uws: &str) {
        assert_eq!(result.len(), lib_res.len());
        for i in 0..result.len() {
            let res: Local<Token> = result[i].clone().into();
            assert_eq!(res, lib_res[i]);
        }
    }

    fn check<T: Clone + std::fmt::Debug + Into<Local<Token>>>(
        res: &Vec<T>,
        lib: &Vec<Local<Token>>,
        _uws: &str,
    ) {
        let mut lib = lib.iter();
        let mut res = res.iter().map(|r| {
            let res: Local<Token> = r.clone().into();
            res
        });
        let mut diff = Vec::new();
        loop {
            match (lib.next(), res.next()) {
                (Some(lw), Some(rw)) => {
                    if *lw != rw {
                        diff.push(format!("LIB:  {:?}", lw));
                        diff.push(format!("TEST: {:?}", rw));
                        diff.push("".to_string())
                    }
                }
                (Some(lw), None) => {
                    diff.push(format!("LIB:  {:?}", lw));
                    diff.push("TEST: ----".to_string());
                    diff.push("".to_string())
                }
                (None, Some(rw)) => {
                    diff.push("LIB:  ----".to_string());
                    diff.push(format!("TEST: {:?}", rw));
                    diff.push("".to_string())
                }
                (None, None) => break,
            }
        }
        if diff.len() > 0 {
            for ln in &diff {
                println!("{}", ln);
            }
            panic!("Diff count: {}", diff.len() / 3);
        }
    }

    #[test]
    fn spaces() {
        let uws = "    spaces    too   many   apces   ";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 4,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 4,
                length: 6,
                token: Token::Word(Word::Word("spaces".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 10,
                length: 4,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 14,
                length: 3,
                token: Token::Word(Word::Word("too".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 17,
                length: 3,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 20,
                length: 4,
                token: Token::Word(Word::Word("many".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 24,
                length: 3,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 27,
                length: 5,
                token: Token::Word(Word::Word("apces".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 32,
                length: 3,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
        ];
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
        //panic!()
    }

    #[test]
    fn numbers() {
        let uws = "(() -2\n()  -2";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 1,
                token: Token::Special(Special::Punctuation('(')),
            },
            PositionalToken {
                source: uws,
                offset: 1,
                length: 1,
                token: Token::Special(Special::Punctuation('(')),
            },
            PositionalToken {
                source: uws,
                offset: 2,
                length: 1,
                token: Token::Special(Special::Punctuation(')')),
            },
            PositionalToken {
                source: uws,
                offset: 3,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 4,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(-2))),
            },
            PositionalToken {
                source: uws,
                offset: 6,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 7,
                length: 1,
                token: Token::Special(Special::Punctuation('(')),
            },
            PositionalToken {
                source: uws,
                offset: 8,
                length: 1,
                token: Token::Special(Special::Punctuation(')')),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 11,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(-2))),
            },
        ];
        let lib_res = uws
            .into_tokenizer({
                TokenizerParams::default()
                    .add_option(TokenizerOptions::SplitDot)
                    .add_option(TokenizerOptions::SplitUnderscore)
                    .add_option(TokenizerOptions::SplitColon)
                    .add_option(TokenizerOptions::MergeWhites)
            })
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn word_with_inner_hyphens() {
        let uws = "–û–ø—Ä–æ¬≠—Å—ã –ø–æ¬≠–∫–∞¬≠–∑—ã¬≠–≤–∞¬≠—é—Ç";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 14,
                token: Token::Word(Word::StrangeWord("–û–ø—Ä–æ¬≠—Å—ã".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 14,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 15,
                length: 28,
                token: Token::Word(Word::StrangeWord("–ø–æ¬≠–∫–∞¬≠–∑—ã¬≠–≤–∞¬≠—é—Ç".to_string())),
            },
        ];
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn mixed_but_word() {
        let uws = "L‚ÄôOreal";
        let result = vec![PositionalToken {
            source: uws,
            offset: 0,
            length: 9,
            token: Token::Word(Word::StrangeWord("L‚ÄôOreal".to_string())),
        }];
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn hashtags() {
        let uws = "#hashtag#hashtag2";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 1,
                token: Token::Special(Special::Punctuation('#')),
            },
            PositionalToken {
                source: uws,
                offset: 1,
                length: 7,
                token: Token::Word(Word::Word("hashtag".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 8,
                length: 1,
                token: Token::Special(Special::Punctuation('#')),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 8,
                token: Token::Word(Word::Numerical(Numerical::Alphanumeric(
                    "hashtag2".to_string(),
                ))),
            },
        ];
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn apostrophe() {
        let uws = "l'oreal; l\u{0060}oreal";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 7,
                token: Token::Word(Word::Word("l'oreal".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 7,
                length: 1,
                token: Token::Special(Special::Punctuation(';')),
            },
            PositionalToken {
                source: uws,
                offset: 8,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 7,
                token: Token::Word(Word::Word("l'oreal".to_string())),
            },
        ];
        let text = Text::new(uws.into_source()).unwrap();
        let lib_res = text
            .into_tokenizer(TokenizerParams::v1())
            .filter_map(|tt| tt.into_original_token_1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn char_tokens() {
        let uws = "[Oxana Putan|1712640565] shared the quick (\"brown\") fox can't jump 32.3 feet, right? 4pda etc. qeq U.S.A  asd\n\n\nBrr, it's 29.3¬∞F!\n –†—É—Å—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #36.6 –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –ø–æ —é–Ω–∏–∫–æ–¥-—Å–ª–æ–≤–∞–º...\nüá∑üá∫ üá∏üáπ\nüë±üèøüë∂üèΩüë®üèΩ\n+Done! –ì–æ—Ç–æ–≤–æ";
        let result = vec![
            CharToken {
                byte_offset: 0,
                byte_length: 1,
                char_offset: 0,
                char_length: 1,
                token: Token::Special(Special::Punctuation('[')),
            },
            CharToken {
                byte_offset: 1,
                byte_length: 5,
                char_offset: 1,
                char_length: 5,
                token: Token::Word(Word::Word("Oxana".to_string())),
            },
            CharToken {
                byte_offset: 6,
                byte_length: 1,
                char_offset: 6,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 7,
                byte_length: 5,
                char_offset: 7,
                char_length: 5,
                token: Token::Word(Word::Word("Putan".to_string())),
            },
            CharToken {
                byte_offset: 12,
                byte_length: 1,
                char_offset: 12,
                char_length: 1,
                token: Token::Special(Special::Punctuation('|')),
            },
            CharToken {
                byte_offset: 13,
                byte_length: 10,
                char_offset: 13,
                char_length: 10,
                token: Token::Word(Word::Number(Number::Integer(1712640565))),
            },
            CharToken {
                byte_offset: 23,
                byte_length: 1,
                char_offset: 23,
                char_length: 1,
                token: Token::Special(Special::Punctuation(']')),
            },
            /*CharToken { byte_offset: 0, byte_length: 24, char_offset: 0, char_length: 24, token: Token::BBCode { left: vec![
            CharToken { byte_offset: 1, byte_length: 5, char_offset: 1, char_length: 5, token: Token::Word(Word::Word("Oxana".to_string())) },
            CharToken { byte_offset: 6, byte_length: 1, char_offset: 6, char_length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            CharToken { byte_offset: 7, byte_length: 5, char_offset: 7, char_length: 5, token: Token::Word(Word::Word("Putan".to_string())) },
            ], right: vec![
            CharToken { byte_offset: 13, byte_length: 10, char_offset: 13, char_length: 10, token: Token::Word(Word::Number(Number::Integer(1712640565))) },
            ] } },*/
            CharToken {
                byte_offset: 24,
                byte_length: 1,
                char_offset: 24,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 25,
                byte_length: 6,
                char_offset: 25,
                char_length: 6,
                token: Token::Word(Word::Word("shared".to_string())),
            },
            CharToken {
                byte_offset: 31,
                byte_length: 1,
                char_offset: 31,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 32,
                byte_length: 3,
                char_offset: 32,
                char_length: 3,
                token: Token::Word(Word::Word("the".to_string())),
            },
            CharToken {
                byte_offset: 35,
                byte_length: 1,
                char_offset: 35,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 36,
                byte_length: 5,
                char_offset: 36,
                char_length: 5,
                token: Token::Word(Word::Word("quick".to_string())),
            },
            CharToken {
                byte_offset: 41,
                byte_length: 1,
                char_offset: 41,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 42,
                byte_length: 1,
                char_offset: 42,
                char_length: 1,
                token: Token::Special(Special::Punctuation('(')),
            },
            CharToken {
                byte_offset: 43,
                byte_length: 1,
                char_offset: 43,
                char_length: 1,
                token: Token::Special(Special::Punctuation('"')),
            },
            CharToken {
                byte_offset: 44,
                byte_length: 5,
                char_offset: 44,
                char_length: 5,
                token: Token::Word(Word::Word("brown".to_string())),
            },
            CharToken {
                byte_offset: 49,
                byte_length: 1,
                char_offset: 49,
                char_length: 1,
                token: Token::Special(Special::Punctuation('"')),
            },
            CharToken {
                byte_offset: 50,
                byte_length: 1,
                char_offset: 50,
                char_length: 1,
                token: Token::Special(Special::Punctuation(')')),
            },
            CharToken {
                byte_offset: 51,
                byte_length: 1,
                char_offset: 51,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 52,
                byte_length: 3,
                char_offset: 52,
                char_length: 3,
                token: Token::Word(Word::Word("fox".to_string())),
            },
            CharToken {
                byte_offset: 55,
                byte_length: 1,
                char_offset: 55,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 56,
                byte_length: 5,
                char_offset: 56,
                char_length: 5,
                token: Token::Word(Word::Word("can\'t".to_string())),
            },
            CharToken {
                byte_offset: 61,
                byte_length: 1,
                char_offset: 61,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 62,
                byte_length: 4,
                char_offset: 62,
                char_length: 4,
                token: Token::Word(Word::Word("jump".to_string())),
            },
            CharToken {
                byte_offset: 66,
                byte_length: 1,
                char_offset: 66,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 67,
                byte_length: 4,
                char_offset: 67,
                char_length: 4,
                token: Token::Word(Word::Number(Number::Float(32.3))),
            },
            CharToken {
                byte_offset: 71,
                byte_length: 1,
                char_offset: 71,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 72,
                byte_length: 4,
                char_offset: 72,
                char_length: 4,
                token: Token::Word(Word::Word("feet".to_string())),
            },
            CharToken {
                byte_offset: 76,
                byte_length: 1,
                char_offset: 76,
                char_length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            CharToken {
                byte_offset: 77,
                byte_length: 1,
                char_offset: 77,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 78,
                byte_length: 5,
                char_offset: 78,
                char_length: 5,
                token: Token::Word(Word::Word("right".to_string())),
            },
            CharToken {
                byte_offset: 83,
                byte_length: 1,
                char_offset: 83,
                char_length: 1,
                token: Token::Special(Special::Punctuation('?')),
            },
            CharToken {
                byte_offset: 84,
                byte_length: 1,
                char_offset: 84,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 85,
                byte_length: 4,
                char_offset: 85,
                char_length: 4,
                token: Token::Word(Word::Numerical(Numerical::Measures("4pda".to_string()))),
            },
            CharToken {
                byte_offset: 89,
                byte_length: 1,
                char_offset: 89,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 90,
                byte_length: 3,
                char_offset: 90,
                char_length: 3,
                token: Token::Word(Word::Word("etc".to_string())),
            },
            CharToken {
                byte_offset: 93,
                byte_length: 1,
                char_offset: 93,
                char_length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            CharToken {
                byte_offset: 94,
                byte_length: 1,
                char_offset: 94,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 95,
                byte_length: 3,
                char_offset: 95,
                char_length: 3,
                token: Token::Word(Word::Word("qeq".to_string())),
            },
            CharToken {
                byte_offset: 98,
                byte_length: 1,
                char_offset: 98,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 99,
                byte_length: 5,
                char_offset: 99,
                char_length: 5,
                token: Token::Word(Word::Word("U.S.A".to_string())),
            },
            CharToken {
                byte_offset: 104,
                byte_length: 2,
                char_offset: 104,
                char_length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 106,
                byte_length: 3,
                char_offset: 106,
                char_length: 3,
                token: Token::Word(Word::Word("asd".to_string())),
            },
            CharToken {
                byte_offset: 109,
                byte_length: 3,
                char_offset: 109,
                char_length: 3,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            CharToken {
                byte_offset: 112,
                byte_length: 3,
                char_offset: 112,
                char_length: 3,
                token: Token::Word(Word::Word("Brr".to_string())),
            },
            CharToken {
                byte_offset: 115,
                byte_length: 1,
                char_offset: 115,
                char_length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            CharToken {
                byte_offset: 116,
                byte_length: 1,
                char_offset: 116,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 117,
                byte_length: 4,
                char_offset: 117,
                char_length: 4,
                token: Token::Word(Word::Word("it\'s".to_string())),
            },
            CharToken {
                byte_offset: 121,
                byte_length: 1,
                char_offset: 121,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 122,
                byte_length: 4,
                char_offset: 122,
                char_length: 4,
                token: Token::Word(Word::Number(Number::Float(29.3))),
            },
            CharToken {
                byte_offset: 126,
                byte_length: 2,
                char_offset: 126,
                char_length: 1,
                token: Token::Special(Special::Symbol('¬∞')),
            },
            CharToken {
                byte_offset: 128,
                byte_length: 1,
                char_offset: 127,
                char_length: 1,
                token: Token::Word(Word::Word("F".to_string())),
            },
            CharToken {
                byte_offset: 129,
                byte_length: 1,
                char_offset: 128,
                char_length: 1,
                token: Token::Special(Special::Punctuation('!')),
            },
            CharToken {
                byte_offset: 130,
                byte_length: 1,
                char_offset: 129,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            CharToken {
                byte_offset: 131,
                byte_length: 1,
                char_offset: 130,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 132,
                byte_length: 14,
                char_offset: 131,
                char_length: 7,
                token: Token::Word(Word::Word("–†—É—Å—Å–∫–æ–µ".to_string())),
            },
            CharToken {
                byte_offset: 146,
                byte_length: 1,
                char_offset: 138,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 147,
                byte_length: 22,
                char_offset: 139,
                char_length: 11,
                token: Token::Word(Word::Word("–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ".to_string())),
            },
            CharToken {
                byte_offset: 169,
                byte_length: 1,
                char_offset: 150,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 170,
                byte_length: 5,
                char_offset: 151,
                char_length: 5,
                token: Token::Struct(Struct::Hashtag("36.6".to_string())),
            },
            CharToken {
                byte_offset: 175,
                byte_length: 1,
                char_offset: 156,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 176,
                byte_length: 6,
                char_offset: 157,
                char_length: 3,
                token: Token::Word(Word::Word("–¥–ª—è".to_string())),
            },
            CharToken {
                byte_offset: 182,
                byte_length: 1,
                char_offset: 160,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 183,
                byte_length: 24,
                char_offset: 161,
                char_length: 12,
                token: Token::Word(Word::Word("—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è".to_string())),
            },
            CharToken {
                byte_offset: 207,
                byte_length: 1,
                char_offset: 173,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 208,
                byte_length: 14,
                char_offset: 174,
                char_length: 7,
                token: Token::Word(Word::Word("–¥–µ–ª–µ–Ω–∏—è".to_string())),
            },
            CharToken {
                byte_offset: 222,
                byte_length: 1,
                char_offset: 181,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 223,
                byte_length: 4,
                char_offset: 182,
                char_length: 2,
                token: Token::Word(Word::Word("–ø–æ".to_string())),
            },
            CharToken {
                byte_offset: 227,
                byte_length: 1,
                char_offset: 184,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 228,
                byte_length: 12,
                char_offset: 185,
                char_length: 6,
                token: Token::Word(Word::Word("—é–Ω–∏–∫–æ–¥".to_string())),
            },
            CharToken {
                byte_offset: 240,
                byte_length: 1,
                char_offset: 191,
                char_length: 1,
                token: Token::Special(Special::Punctuation('-')),
            },
            CharToken {
                byte_offset: 241,
                byte_length: 12,
                char_offset: 192,
                char_length: 6,
                token: Token::Word(Word::Word("—Å–ª–æ–≤–∞–º".to_string())),
            },
            CharToken {
                byte_offset: 253,
                byte_length: 3,
                char_offset: 198,
                char_length: 3,
                token: Token::Special(Special::Punctuation('.')),
            },
            CharToken {
                byte_offset: 256,
                byte_length: 1,
                char_offset: 201,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            CharToken {
                byte_offset: 257,
                byte_length: 8,
                char_offset: 202,
                char_length: 2,
                token: Token::Word(Word::Emoji("russia")),
            },
            CharToken {
                byte_offset: 265,
                byte_length: 1,
                char_offset: 204,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 266,
                byte_length: 8,
                char_offset: 205,
                char_length: 2,
                token: Token::Word(Word::Emoji("sao_tome_and_principe")),
            },
            CharToken {
                byte_offset: 274,
                byte_length: 1,
                char_offset: 207,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            CharToken {
                byte_offset: 275,
                byte_length: 8,
                char_offset: 208,
                char_length: 2,
                token: Token::Word(Word::Emoji("blond_haired_person_dark_skin_tone")),
            },
            CharToken {
                byte_offset: 283,
                byte_length: 8,
                char_offset: 210,
                char_length: 2,
                token: Token::Word(Word::Emoji("baby_medium_skin_tone")),
            },
            CharToken {
                byte_offset: 291,
                byte_length: 8,
                char_offset: 212,
                char_length: 2,
                token: Token::Word(Word::Emoji("man_medium_skin_tone")),
            },
            CharToken {
                byte_offset: 299,
                byte_length: 1,
                char_offset: 214,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            CharToken {
                byte_offset: 300,
                byte_length: 1,
                char_offset: 215,
                char_length: 1,
                token: Token::Special(Special::Punctuation('+')),
            },
            CharToken {
                byte_offset: 301,
                byte_length: 4,
                char_offset: 216,
                char_length: 4,
                token: Token::Word(Word::Word("Done".to_string())),
            },
            CharToken {
                byte_offset: 305,
                byte_length: 1,
                char_offset: 220,
                char_length: 1,
                token: Token::Special(Special::Punctuation('!')),
            },
            CharToken {
                byte_offset: 306,
                byte_length: 1,
                char_offset: 221,
                char_length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            CharToken {
                byte_offset: 307,
                byte_length: 12,
                char_offset: 222,
                char_length: 6,
                token: Token::Word(Word::Word("–ì–æ—Ç–æ–≤–æ".to_string())),
            },
        ];

        let lib_res = uws
            .into_tokenizer(TokenizerParams::complex())
            .collect::<Vec<_>>();

        //print_cresult(); panic!();
        check_cresults(&result, &lib_res, uws);
    }

    #[test]
    fn general_default() {
        let uws = "The quick (\"brown\") fox can't jump 32.3 feet, right? 4pda etc. qeq U.S.A  asd\n\n\nBrr, it's 29.3¬∞F!\n –†—É—Å—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #36.6 –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –ø–æ —é–Ω–∏–∫–æ–¥-—Å–ª–æ–≤–∞–º...\n";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 3,
                token: Token::Word(Word::Word("The".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 3,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 4,
                length: 5,
                token: Token::Word(Word::Word("quick".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 10,
                length: 1,
                token: Token::Special(Special::Punctuation('(')),
            },
            PositionalToken {
                source: uws,
                offset: 11,
                length: 1,
                token: Token::Special(Special::Punctuation('"')),
            },
            PositionalToken {
                source: uws,
                offset: 12,
                length: 5,
                token: Token::Word(Word::Word("brown".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 17,
                length: 1,
                token: Token::Special(Special::Punctuation('"')),
            },
            PositionalToken {
                source: uws,
                offset: 18,
                length: 1,
                token: Token::Special(Special::Punctuation(')')),
            },
            PositionalToken {
                source: uws,
                offset: 19,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 20,
                length: 3,
                token: Token::Word(Word::Word("fox".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 23,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 24,
                length: 5,
                token: Token::Word(Word::Word("can\'t".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 29,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 30,
                length: 4,
                token: Token::Word(Word::Word("jump".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 34,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 35,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(32.3))),
            },
            PositionalToken {
                source: uws,
                offset: 39,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 40,
                length: 4,
                token: Token::Word(Word::Word("feet".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 44,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 45,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 46,
                length: 5,
                token: Token::Word(Word::Word("right".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 51,
                length: 1,
                token: Token::Special(Special::Punctuation('?')),
            },
            PositionalToken {
                source: uws,
                offset: 52,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 53,
                length: 4,
                token: Token::Word(Word::Numerical(Numerical::Measures("4pda".to_string()))),
            }, // TODO
            PositionalToken {
                source: uws,
                offset: 57,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 58,
                length: 3,
                token: Token::Word(Word::Word("etc".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 61,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 62,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 63,
                length: 3,
                token: Token::Word(Word::Word("qeq".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 66,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 67,
                length: 1,
                token: Token::Word(Word::Word("U".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 68,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 69,
                length: 1,
                token: Token::Word(Word::Word("S".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 70,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 71,
                length: 1,
                token: Token::Word(Word::Word("A".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 72,
                length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 74,
                length: 3,
                token: Token::Word(Word::Word("asd".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 77,
                length: 3,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 80,
                length: 3,
                token: Token::Word(Word::Word("Brr".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 83,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 84,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 85,
                length: 4,
                token: Token::Word(Word::Word("it\'s".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 89,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 90,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(29.3))),
            },
            PositionalToken {
                source: uws,
                offset: 94,
                length: 2,
                token: Token::Special(Special::Symbol('¬∞')),
            },
            PositionalToken {
                source: uws,
                offset: 96,
                length: 1,
                token: Token::Word(Word::Word("F".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 97,
                length: 1,
                token: Token::Special(Special::Punctuation('!')),
            },
            PositionalToken {
                source: uws,
                offset: 98,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 99,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 100,
                length: 14,
                token: Token::Word(Word::Word("–†—É—Å—Å–∫–æ–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 114,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 115,
                length: 22,
                token: Token::Word(Word::Word("–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 137,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 138,
                length: 1,
                token: Token::Special(Special::Punctuation('#')),
            },
            PositionalToken {
                source: uws,
                offset: 139,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(36.6))),
            },
            PositionalToken {
                source: uws,
                offset: 143,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 144,
                length: 6,
                token: Token::Word(Word::Word("–¥–ª—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 150,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 151,
                length: 24,
                token: Token::Word(Word::Word("—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 175,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 176,
                length: 14,
                token: Token::Word(Word::Word("–¥–µ–ª–µ–Ω–∏—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 190,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 191,
                length: 4,
                token: Token::Word(Word::Word("–ø–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 195,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 196,
                length: 12,
                token: Token::Word(Word::Word("—é–Ω–∏–∫–æ–¥".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 208,
                length: 1,
                token: Token::Special(Special::Punctuation('-')),
            },
            PositionalToken {
                source: uws,
                offset: 209,
                length: 12,
                token: Token::Word(Word::Word("—Å–ª–æ–≤–∞–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 221,
                length: 3,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 224,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
        ];
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn general_no_split() {
        let uws = "The quick (\"brown\") fox can't jump 32.3 feet, right? 4pda etc. qeq U.S.A  asd\n\n\nBrr, it's 29.3¬∞F!\n –†—É—Å—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #36.6 –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –ø–æ —é–Ω–∏–∫–æ–¥-—Å–ª–æ–≤–∞–º...\n";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 3,
                token: Token::Word(Word::Word("The".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 3,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 4,
                length: 5,
                token: Token::Word(Word::Word("quick".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 10,
                length: 1,
                token: Token::Special(Special::Punctuation('(')),
            },
            PositionalToken {
                source: uws,
                offset: 11,
                length: 1,
                token: Token::Special(Special::Punctuation('"')),
            },
            PositionalToken {
                source: uws,
                offset: 12,
                length: 5,
                token: Token::Word(Word::Word("brown".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 17,
                length: 1,
                token: Token::Special(Special::Punctuation('"')),
            },
            PositionalToken {
                source: uws,
                offset: 18,
                length: 1,
                token: Token::Special(Special::Punctuation(')')),
            },
            PositionalToken {
                source: uws,
                offset: 19,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 20,
                length: 3,
                token: Token::Word(Word::Word("fox".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 23,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 24,
                length: 5,
                token: Token::Word(Word::Word("can\'t".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 29,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 30,
                length: 4,
                token: Token::Word(Word::Word("jump".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 34,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 35,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(32.3))),
            },
            PositionalToken {
                source: uws,
                offset: 39,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 40,
                length: 4,
                token: Token::Word(Word::Word("feet".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 44,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 45,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 46,
                length: 5,
                token: Token::Word(Word::Word("right".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 51,
                length: 1,
                token: Token::Special(Special::Punctuation('?')),
            },
            PositionalToken {
                source: uws,
                offset: 52,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 53,
                length: 4,
                token: Token::Word(Word::Numerical(Numerical::Measures("4pda".to_string()))),
            }, // TODO
            PositionalToken {
                source: uws,
                offset: 57,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 58,
                length: 3,
                token: Token::Word(Word::Word("etc".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 61,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 62,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 63,
                length: 3,
                token: Token::Word(Word::Word("qeq".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 66,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 67,
                length: 5,
                token: Token::Word(Word::Word("U.S.A".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 72,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 73,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 74,
                length: 3,
                token: Token::Word(Word::Word("asd".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 77,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 78,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 79,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 80,
                length: 3,
                token: Token::Word(Word::Word("Brr".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 83,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 84,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 85,
                length: 4,
                token: Token::Word(Word::Word("it\'s".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 89,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 90,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(29.3))),
            },
            PositionalToken {
                source: uws,
                offset: 94,
                length: 2,
                token: Token::Special(Special::Symbol('¬∞')),
            },
            PositionalToken {
                source: uws,
                offset: 96,
                length: 1,
                token: Token::Word(Word::Word("F".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 97,
                length: 1,
                token: Token::Special(Special::Punctuation('!')),
            },
            PositionalToken {
                source: uws,
                offset: 98,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 99,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 100,
                length: 14,
                token: Token::Word(Word::Word("–†—É—Å—Å–∫–æ–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 114,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 115,
                length: 22,
                token: Token::Word(Word::Word("–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 137,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 138,
                length: 1,
                token: Token::Special(Special::Punctuation('#')),
            },
            PositionalToken {
                source: uws,
                offset: 139,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(36.6))),
            },
            PositionalToken {
                source: uws,
                offset: 143,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 144,
                length: 6,
                token: Token::Word(Word::Word("–¥–ª—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 150,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 151,
                length: 24,
                token: Token::Word(Word::Word("—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 175,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 176,
                length: 14,
                token: Token::Word(Word::Word("–¥–µ–ª–µ–Ω–∏—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 190,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 191,
                length: 4,
                token: Token::Word(Word::Word("–ø–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 195,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 196,
                length: 12,
                token: Token::Word(Word::Word("—é–Ω–∏–∫–æ–¥".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 208,
                length: 1,
                token: Token::Special(Special::Punctuation('-')),
            },
            PositionalToken {
                source: uws,
                offset: 209,
                length: 12,
                token: Token::Word(Word::Word("—Å–ª–æ–≤–∞–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 221,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 222,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 223,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 224,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
        ];
        let lib_res = uws.into_tokenizer(Default::default()).collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn general_complex() {
        let uws = "The quick (\"brown\") fox can't jump 32.3 feet, right? 4pda etc. qeq U.S.A  asd\n\n\nBrr, it's 29.3¬∞F!\n –†—É—Å—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ #36.6 –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–ª–µ–Ω–∏—è –ø–æ —é–Ω–∏–∫–æ–¥-—Å–ª–æ–≤–∞–º...\n";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 3,
                token: Token::Word(Word::Word("The".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 3,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 4,
                length: 5,
                token: Token::Word(Word::Word("quick".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 10,
                length: 1,
                token: Token::Special(Special::Punctuation('(')),
            },
            PositionalToken {
                source: uws,
                offset: 11,
                length: 1,
                token: Token::Special(Special::Punctuation('"')),
            },
            PositionalToken {
                source: uws,
                offset: 12,
                length: 5,
                token: Token::Word(Word::Word("brown".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 17,
                length: 1,
                token: Token::Special(Special::Punctuation('"')),
            },
            PositionalToken {
                source: uws,
                offset: 18,
                length: 1,
                token: Token::Special(Special::Punctuation(')')),
            },
            PositionalToken {
                source: uws,
                offset: 19,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 20,
                length: 3,
                token: Token::Word(Word::Word("fox".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 23,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 24,
                length: 5,
                token: Token::Word(Word::Word("can\'t".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 29,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 30,
                length: 4,
                token: Token::Word(Word::Word("jump".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 34,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 35,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(32.3))),
            },
            PositionalToken {
                source: uws,
                offset: 39,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 40,
                length: 4,
                token: Token::Word(Word::Word("feet".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 44,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 45,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 46,
                length: 5,
                token: Token::Word(Word::Word("right".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 51,
                length: 1,
                token: Token::Special(Special::Punctuation('?')),
            },
            PositionalToken {
                source: uws,
                offset: 52,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 53,
                length: 4,
                token: Token::Word(Word::Numerical(Numerical::Measures("4pda".to_string()))),
            }, // TODO
            PositionalToken {
                source: uws,
                offset: 57,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 58,
                length: 3,
                token: Token::Word(Word::Word("etc".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 61,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 62,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 63,
                length: 3,
                token: Token::Word(Word::Word("qeq".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 66,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 67,
                length: 5,
                token: Token::Word(Word::Word("U.S.A".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 72,
                length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 74,
                length: 3,
                token: Token::Word(Word::Word("asd".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 77,
                length: 3,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 80,
                length: 3,
                token: Token::Word(Word::Word("Brr".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 83,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 84,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 85,
                length: 4,
                token: Token::Word(Word::Word("it\'s".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 89,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 90,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(29.3))),
            },
            PositionalToken {
                source: uws,
                offset: 94,
                length: 2,
                token: Token::Special(Special::Symbol('¬∞')),
            },
            PositionalToken {
                source: uws,
                offset: 96,
                length: 1,
                token: Token::Word(Word::Word("F".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 97,
                length: 1,
                token: Token::Special(Special::Punctuation('!')),
            },
            PositionalToken {
                source: uws,
                offset: 98,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 99,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 100,
                length: 14,
                token: Token::Word(Word::Word("–†—É—Å—Å–∫–æ–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 114,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 115,
                length: 22,
                token: Token::Word(Word::Word("–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 137,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 138,
                length: 5,
                token: Token::Struct(Struct::Hashtag("36.6".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 143,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 144,
                length: 6,
                token: Token::Word(Word::Word("–¥–ª—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 150,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 151,
                length: 24,
                token: Token::Word(Word::Word("—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 175,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 176,
                length: 14,
                token: Token::Word(Word::Word("–¥–µ–ª–µ–Ω–∏—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 190,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 191,
                length: 4,
                token: Token::Word(Word::Word("–ø–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 195,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 196,
                length: 12,
                token: Token::Word(Word::Word("—é–Ω–∏–∫–æ–¥".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 208,
                length: 1,
                token: Token::Special(Special::Punctuation('-')),
            },
            PositionalToken {
                source: uws,
                offset: 209,
                length: 12,
                token: Token::Word(Word::Word("—Å–ª–æ–≤–∞–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 221,
                length: 3,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 224,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
        ];
        let lib_res = uws
            .into_tokenizer(TokenizerParams::complex())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn plus_minus() {
        let uws = "+23 -4.5 -34 +25.7 - 2 + 5.6";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(23))),
            },
            PositionalToken {
                source: uws,
                offset: 3,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 4,
                length: 4,
                token: Token::Word(Word::Number(Number::Float(-4.5))),
            },
            PositionalToken {
                source: uws,
                offset: 8,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(-34))),
            },
            PositionalToken {
                source: uws,
                offset: 12,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 13,
                length: 5,
                token: Token::Word(Word::Number(Number::Float(25.7))),
            },
            PositionalToken {
                source: uws,
                offset: 18,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 19,
                length: 1,
                token: Token::Special(Special::Punctuation('-')),
            },
            PositionalToken {
                source: uws,
                offset: 20,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 21,
                length: 1,
                token: Token::Word(Word::Number(Number::Integer(2))),
            },
            PositionalToken {
                source: uws,
                offset: 22,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 23,
                length: 1,
                token: Token::Special(Special::Punctuation('+')),
            },
            PositionalToken {
                source: uws,
                offset: 24,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 25,
                length: 3,
                token: Token::Word(Word::Number(Number::Float(5.6))),
            },
        ];
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check(&result, &lib_res, uws);
        //print_result(&lib_res); panic!("")
    }

    #[test]
    #[ignore]
    fn woman_bouncing_ball() {
        let uws = "\u{26f9}\u{200d}\u{2640}";
        let result = vec![PositionalToken {
            source: uws,
            offset: 0,
            length: 9,
            token: Token::Word(Word::Emoji("woman_bouncing_ball")),
        }];
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
        //print_result(&lib_res); panic!("")
    }

    #[test]
    fn emoji_and_rusabbr_default() {
        let uws = "üá∑üá∫ üá∏üáπ\nüë±üèøüë∂üèΩüë®üèΩ\nüë±\n–°.–°.–°.–†.\nüë®‚Äçüë©‚Äçüë¶‚Äçüë¶\nüß†\n";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 8,
                token: Token::Word(Word::Emoji("russia")),
            },
            PositionalToken {
                source: uws,
                offset: 8,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 8,
                token: Token::Word(Word::Emoji("sao_tome_and_principe")),
            },
            PositionalToken {
                source: uws,
                offset: 17,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 18,
                length: 8,
                token: Token::Word(Word::Emoji("blond_haired_person_dark_skin_tone")),
            },
            PositionalToken {
                source: uws,
                offset: 26,
                length: 8,
                token: Token::Word(Word::Emoji("baby_medium_skin_tone")),
            },
            PositionalToken {
                source: uws,
                offset: 34,
                length: 8,
                token: Token::Word(Word::Emoji("man_medium_skin_tone")),
            },
            PositionalToken {
                source: uws,
                offset: 42,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 43,
                length: 4,
                token: Token::Word(Word::Emoji("blond_haired_person")),
            },
            PositionalToken {
                source: uws,
                offset: 47,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 48,
                length: 2,
                token: Token::Word(Word::Word("–°".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 50,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 51,
                length: 2,
                token: Token::Word(Word::Word("–°".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 53,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 54,
                length: 2,
                token: Token::Word(Word::Word("–°".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 56,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 57,
                length: 2,
                token: Token::Word(Word::Word("–†".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 59,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 60,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 61,
                length: 25,
                token: Token::Word(Word::Emoji("family_man_woman_boy_boy")),
            },
            PositionalToken {
                source: uws,
                offset: 86,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 87,
                length: 4,
                token: Token::Word(Word::Emoji("brain")),
            },
            PositionalToken {
                source: uws,
                offset: 91,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
        ];

        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
        //print_result(&lib_res); panic!();
    }

    #[test]
    fn emoji_and_rusabbr_no_split() {
        let uws = "üá∑üá∫ üá∏üáπ\nüë±üèøüë∂üèΩüë®üèΩ\nüë±\n–°.–°.–°.–†.\nüë®‚Äçüë©‚Äçüë¶‚Äçüë¶\nüß†\n";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 8,
                token: Token::Word(Word::Emoji("russia")),
            },
            PositionalToken {
                source: uws,
                offset: 8,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 8,
                token: Token::Word(Word::Emoji("sao_tome_and_principe")),
            },
            PositionalToken {
                source: uws,
                offset: 17,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 18,
                length: 8,
                token: Token::Word(Word::Emoji("blond_haired_person_dark_skin_tone")),
            },
            PositionalToken {
                source: uws,
                offset: 26,
                length: 8,
                token: Token::Word(Word::Emoji("baby_medium_skin_tone")),
            },
            PositionalToken {
                source: uws,
                offset: 34,
                length: 8,
                token: Token::Word(Word::Emoji("man_medium_skin_tone")),
            },
            PositionalToken {
                source: uws,
                offset: 42,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 43,
                length: 4,
                token: Token::Word(Word::Emoji("blond_haired_person")),
            },
            PositionalToken {
                source: uws,
                offset: 47,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 48,
                length: 11,
                token: Token::Word(Word::Word("–°.–°.–°.–†".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 59,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 60,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 61,
                length: 25,
                token: Token::Word(Word::Emoji("family_man_woman_boy_boy")),
            },
            PositionalToken {
                source: uws,
                offset: 86,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 87,
                length: 4,
                token: Token::Word(Word::Emoji("brain")),
            },
            PositionalToken {
                source: uws,
                offset: 91,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
        ];

        let lib_res = uws.into_tokenizer(Default::default()).collect::<Vec<_>>();
        check_results(&result, &lib_res, uws);
        //print_result(&lib_res); panic!();
    }

    /*#[test]
    fn hashtags_mentions_urls() {
        let uws = "\nSome ##text with #hashtags and @other components\nadfa wdsfdf asdf asd http://asdfasdfsd.com/fasdfd/sadfsadf/sdfas/12312_12414/asdf?fascvx=fsfwer&dsdfasdf=fasdf#fasdf asdfa sdfa sdf\nasdfas df asd who@bla-bla.com asdfas df asdfsd\n";
        let result = vec![
            PositionalToken { source: uws, offset: 0, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { source: uws, offset: 1, length: 4, token: Token::Word(Word::Word("Some".to_string())) },
            PositionalToken { source: uws, offset: 5, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 6, length: 2, token: Token::Special(Special::Punctuation("##".to_string())) },
            PositionalToken { source: uws, offset: 8, length: 4, token: Token::Word(Word::Word("text".to_string())) },
            PositionalToken { source: uws, offset: 12, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 13, length: 4, token: Token::Word(Word::Word("with".to_string())) },
            PositionalToken { source: uws, offset: 17, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 18, length: 9, token: Token::Struct(Struct::Hashtag("hashtags".to_string())) },
            PositionalToken { source: uws, offset: 27, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 28, length: 3, token: Token::Word(Word::Word("and".to_string())) },
            PositionalToken { source: uws, offset: 31, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 32, length: 6, token: Token::Struct(Struct::Mention("other".to_string())) },
            PositionalToken { source: uws, offset: 38, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 39, length: 10, token: Token::Word(Word::Word("components".to_string())) },
            PositionalToken { source: uws, offset: 49, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { source: uws, offset: 50, length: 4, token: Token::Word(Word::Word("adfa".to_string())) },
            PositionalToken { source: uws, offset: 54, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 55, length: 6, token: Token::Word(Word::Word("wdsfdf".to_string())) },
            PositionalToken { source: uws, offset: 61, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 62, length: 4, token: Token::Word(Word::Word("asdf".to_string())) },
            PositionalToken { source: uws, offset: 66, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 67, length: 3, token: Token::Word(Word::Word("asd".to_string())) },
            PositionalToken { source: uws, offset: 70, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 71, length: 95, token: Token::Struct(Struct::Url("http://asdfasdfsd.com/fasdfd/sadfsadf/sdfas/12312_12414/asdf?fascvx=fsfwer&dsdfasdf=fasdf#fasdf".to_string())) },
            PositionalToken { source: uws, offset: 166, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 167, length: 5, token: Token::Word(Word::Word("asdfa".to_string())) },
            PositionalToken { source: uws, offset: 172, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 173, length: 4, token: Token::Word(Word::Word("sdfa".to_string())) },
            PositionalToken { source: uws, offset: 177, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 178, length: 3, token: Token::Word(Word::Word("sdf".to_string())) },
            PositionalToken { source: uws, offset: 181, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { source: uws, offset: 182, length: 6, token: Token::Word(Word::Word("asdfas".to_string())) },
            PositionalToken { source: uws, offset: 188, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 189, length: 2, token: Token::Word(Word::Word("df".to_string())) },
            PositionalToken { source: uws, offset: 191, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 192, length: 3, token: Token::Word(Word::Word("asd".to_string())) },
            PositionalToken { source: uws, offset: 195, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 196, length: 3, token: Token::Word(Word::Word("who".to_string())) },
            PositionalToken { source: uws, offset: 199, length: 4, token: Token::Struct(Struct::Mention("bla".to_string())) },
            PositionalToken { source: uws, offset: 203, length: 1, token: Token::Special(Special::Punctuation('-')) },
            PositionalToken { source: uws, offset: 204, length: 7, token: Token::Word(Word::Word("bla.com".to_string())) },
            PositionalToken { source: uws, offset: 211, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 212, length: 6, token: Token::Word(Word::Word("asdfas".to_string())) },
            PositionalToken { source: uws, offset: 218, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 219, length: 2, token: Token::Word(Word::Word("df".to_string())) },
            PositionalToken { source: uws, offset: 221, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { source: uws, offset: 222, length: 6, token: Token::Word(Word::Word("asdfsd".to_string())) },
            PositionalToken { source: uws, offset: 228, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            ];
        let lib_res = uws.into_tokenizer(TokenizerParams::complex()).collect::<Vec<_>>();
        check_results(&result,&lib_res,uws);
        //print_result(&lib_res); panic!("")
    }*/

    /*#[test]
    fn bb_code() {
        let uws = "[Oxana Putan|1712640565] shared a [post|100001150683379_1873048549410150]. \nAndrew\n[link|https://www.facebook.com/100001150683379/posts/1873048549410150]\n–î—Ä—É–∑—å—è –º–æ–∏, –∏–∑–¥–∞—Ç–µ–ª–∏, —Ä–µ–¥–∞–∫—Ç–æ—Ä—ã, –ø—Ä–æ—Å–≤–µ—Ç–∏—Ç–µ–ª–∏, –∫—É–ª—å—Ç—É—Ä—Ç—Ä–µ–≥–µ—Ä—ã, —Å—É–±—ä–µ–∫—Ç—ã –º–∏—Ä–æ–≤–æ–≥–æ —Ä—ã–Ω–∫–∞ –∏ —Ç—É —Ö—É–º –∏—Ç –µ—â—ë –º–µ–π –∫–æ–Ω—Å—ë—Ä–Ω.\n–ù–∞ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç —è –ª–∏—à–µ–Ω –±—ã–ª–æ–π –ø–æ–¥–≤–∏–∂–Ω–æ—Å—Ç–∏, —Ö–æ—Ç—å –∏ –∫–æ–≤—ã–ª—è—é –ø–æ –±–æ–ª—å–Ω–∏—á–Ω—ã—Ö –∫–æ—Ä–∏–¥–æ—Ä–∞–º –ø–æ —Ä–∞–∑–Ω—ã–º –Ω—É–∂–¥–∞–º –∏ –∑–∞ –∫–∏–ø—è—Ç–∫–æ–º.\n–í—Ä–∞—á–∏ –æ–±–µ—â–∞—é—Ç –º–Ω–µ –∑–∞–∂–∏–≤–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ä—Å—Ç—ã—Ö —Ä–∞–Ω –º–æ–∏—Ö –≤ —Ç–µ—á–µ–Ω–∏–µ –ø–æ–ª—É–≥–æ–¥–∞ –∏ –Ω–∞ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥ –º–æ–∂–Ω–æ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—Ç—å —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –¥–æ–º–∞—à–Ω–∏–π –æ–±—Ä–∞–∑ –∂–∏–∑–Ω–∏.\n[|]";
        let result = vec![
            PositionalToken { offset: 0, length: 24, token: Token::BBCode { left: vec![
                PositionalToken { offset: 1, length: 5, token: Token::Word(Word::Word("Oxana".to_string())) },
                PositionalToken { offset: 6, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
                PositionalToken { offset: 7, length: 5, token: Token::Word(Word::Word("Putan".to_string())) },
                ], right: vec![
                PositionalToken { offset: 13, length: 10, token: Token::Word(Word::Number(Number::Integer(1712640565))) },
                ] } },
            PositionalToken { offset: 24, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 25, length: 6, token: Token::Word(Word::Word("shared".to_string())) },
            PositionalToken { offset: 31, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 32, length: 1, token: Token::Word(Word::Word("a".to_string())) },
            PositionalToken { offset: 33, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 34, length: 39, token: Token::BBCode { left: vec![
                PositionalToken { offset: 35, length: 4, token: Token::Word(Word::Word("post".to_string())) },
                ], right: vec![
                PositionalToken { offset: 40, length: 32, token: Token::Word(Word::Numerical(Numerical::Alphanumeric("100001150683379_1873048549410150".to_string()))) },
                ] } },
            PositionalToken { offset: 73, length: 1, token: Token::Special(Special::Punctuation('.')) },
            PositionalToken { offset: 74, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 75, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { offset: 76, length: 6, token: Token::Word(Word::Word("Andrew".to_string())) },
            PositionalToken { offset: 82, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { offset: 83, length: 70, token: Token::BBCode { left: vec![
                PositionalToken { offset: 84, length: 4, token: Token::Word(Word::Word("link".to_string())) },
                ], right: vec![
                PositionalToken { offset: 89, length: 63, token: Token::Struct(Struct::Url("https://www.facebook.com/100001150683379/posts/1873048549410150".to_string())) },
                ] } },
            PositionalToken { offset: 153, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { offset: 154, length: 12, token: Token::Word(Word::Word("–î—Ä—É–∑—å—è".to_string())) },
            PositionalToken { offset: 166, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 167, length: 6, token: Token::Word(Word::Word("–º–æ–∏".to_string())) },
            PositionalToken { offset: 173, length: 1, token: Token::Special(Special::Punctuation(',')) },
            PositionalToken { offset: 174, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 175, length: 16, token: Token::Word(Word::Word("–∏–∑–¥–∞—Ç–µ–ª–∏".to_string())) },
            PositionalToken { offset: 191, length: 1, token: Token::Special(Special::Punctuation(',')) },
            PositionalToken { offset: 192, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 193, length: 18, token: Token::Word(Word::Word("—Ä–µ–¥–∞–∫—Ç–æ—Ä—ã".to_string())) },
            PositionalToken { offset: 211, length: 1, token: Token::Special(Special::Punctuation(',')) },
            PositionalToken { offset: 212, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 213, length: 24, token: Token::Word(Word::Word("–ø—Ä–æ—Å–≤–µ—Ç–∏—Ç–µ–ª–∏".to_string())) },
            PositionalToken { offset: 237, length: 1, token: Token::Special(Special::Punctuation(',')) },
            PositionalToken { offset: 238, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 239, length: 28, token: Token::Word(Word::Word("–∫—É–ª—å—Ç—É—Ä—Ç—Ä–µ–≥–µ—Ä—ã".to_string())) },
            PositionalToken { offset: 267, length: 1, token: Token::Special(Special::Punctuation(',')) },
            PositionalToken { offset: 268, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 269, length: 16, token: Token::Word(Word::Word("—Å—É–±—ä–µ–∫—Ç—ã".to_string())) },
            PositionalToken { offset: 285, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 286, length: 16, token: Token::Word(Word::Word("–º–∏—Ä–æ–≤–æ–≥–æ".to_string())) },
            PositionalToken { offset: 302, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 303, length: 10, token: Token::Word(Word::Word("—Ä—ã–Ω–∫–∞".to_string())) },
            PositionalToken { offset: 313, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 314, length: 2, token: Token::Word(Word::Word("–∏".to_string())) },
            PositionalToken { offset: 316, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 317, length: 4, token: Token::Word(Word::Word("—Ç—É".to_string())) },
            PositionalToken { offset: 321, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 322, length: 6, token: Token::Word(Word::Word("—Ö—É–º".to_string())) },
            PositionalToken { offset: 328, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 329, length: 4, token: Token::Word(Word::Word("–∏—Ç".to_string())) },
            PositionalToken { offset: 333, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 334, length: 6, token: Token::Word(Word::Word("–µ—â—ë".to_string())) },
            PositionalToken { offset: 340, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 341, length: 6, token: Token::Word(Word::Word("–º–µ–π".to_string())) },
            PositionalToken { offset: 347, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 348, length: 14, token: Token::Word(Word::Word("–∫–æ–Ω—Å—ë—Ä–Ω".to_string())) },
            PositionalToken { offset: 362, length: 1, token: Token::Special(Special::Punctuation('.')) },
            PositionalToken { offset: 363, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { offset: 364, length: 4, token: Token::Word(Word::Word("–ù–∞".to_string())) },
            PositionalToken { offset: 368, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 369, length: 14, token: Token::Word(Word::Word("—Ç–µ–∫—É—â–∏–π".to_string())) },
            PositionalToken { offset: 383, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 384, length: 12, token: Token::Word(Word::Word("–º–æ–º–µ–Ω—Ç".to_string())) },
            PositionalToken { offset: 396, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 397, length: 2, token: Token::Word(Word::Word("—è".to_string())) },
            PositionalToken { offset: 399, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 400, length: 10, token: Token::Word(Word::Word("–ª–∏—à–µ–Ω".to_string())) },
            PositionalToken { offset: 410, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 411, length: 10, token: Token::Word(Word::Word("–±—ã–ª–æ–π".to_string())) },
            PositionalToken { offset: 421, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 422, length: 22, token: Token::Word(Word::Word("–ø–æ–¥–≤–∏–∂–Ω–æ—Å—Ç–∏".to_string())) },
            PositionalToken { offset: 444, length: 1, token: Token::Special(Special::Punctuation(',')) },
            PositionalToken { offset: 445, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 446, length: 8, token: Token::Word(Word::Word("—Ö–æ—Ç—å".to_string())) },
            PositionalToken { offset: 454, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 455, length: 2, token: Token::Word(Word::Word("–∏".to_string())) },
            PositionalToken { offset: 457, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 458, length: 14, token: Token::Word(Word::Word("–∫–æ–≤—ã–ª—è—é".to_string())) },
            PositionalToken { offset: 472, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 473, length: 4, token: Token::Word(Word::Word("–ø–æ".to_string())) },
            PositionalToken { offset: 477, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 478, length: 20, token: Token::Word(Word::Word("–±–æ–ª—å–Ω–∏—á–Ω—ã—Ö".to_string())) },
            PositionalToken { offset: 498, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 499, length: 18, token: Token::Word(Word::Word("–∫–æ—Ä–∏–¥–æ—Ä–∞–º".to_string())) },
            PositionalToken { offset: 517, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 518, length: 4, token: Token::Word(Word::Word("–ø–æ".to_string())) },
            PositionalToken { offset: 522, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 523, length: 12, token: Token::Word(Word::Word("—Ä–∞–∑–Ω—ã–º".to_string())) },
            PositionalToken { offset: 535, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 536, length: 12, token: Token::Word(Word::Word("–Ω—É–∂–¥–∞–º".to_string())) },
            PositionalToken { offset: 548, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 549, length: 2, token: Token::Word(Word::Word("–∏".to_string())) },
            PositionalToken { offset: 551, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 552, length: 4, token: Token::Word(Word::Word("–∑–∞".to_string())) },
            PositionalToken { offset: 556, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 557, length: 16, token: Token::Word(Word::Word("–∫–∏–ø—è—Ç–∫–æ–º".to_string())) },
            PositionalToken { offset: 573, length: 1, token: Token::Special(Special::Punctuation('.')) },
            PositionalToken { offset: 574, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { offset: 575, length: 10, token: Token::Word(Word::Word("–í—Ä–∞—á–∏".to_string())) },
            PositionalToken { offset: 585, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 586, length: 14, token: Token::Word(Word::Word("–æ–±–µ—â–∞—é—Ç".to_string())) },
            PositionalToken { offset: 600, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 601, length: 6, token: Token::Word(Word::Word("–º–Ω–µ".to_string())) },
            PositionalToken { offset: 607, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 608, length: 20, token: Token::Word(Word::Word("–∑–∞–∂–∏–≤–ª–µ–Ω–∏–µ".to_string())) },
            PositionalToken { offset: 628, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 629, length: 18, token: Token::Word(Word::Word("–æ—Ç–≤–µ—Ä—Å—Ç—ã—Ö".to_string())) },
            PositionalToken { offset: 647, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 648, length: 6, token: Token::Word(Word::Word("—Ä–∞–Ω".to_string())) },
            PositionalToken { offset: 654, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 655, length: 8, token: Token::Word(Word::Word("–º–æ–∏—Ö".to_string())) },
            PositionalToken { offset: 663, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 664, length: 2, token: Token::Word(Word::Word("–≤".to_string())) },
            PositionalToken { offset: 666, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 667, length: 14, token: Token::Word(Word::Word("—Ç–µ—á–µ–Ω–∏–µ".to_string())) },
            PositionalToken { offset: 681, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 682, length: 16, token: Token::Word(Word::Word("–ø–æ–ª—É–≥–æ–¥–∞".to_string())) },
            PositionalToken { offset: 698, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 699, length: 2, token: Token::Word(Word::Word("–∏".to_string())) },
            PositionalToken { offset: 701, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 702, length: 4, token: Token::Word(Word::Word("–Ω–∞".to_string())) },
            PositionalToken { offset: 706, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 707, length: 8, token: Token::Word(Word::Word("—ç—Ç–æ—Ç".to_string())) },
            PositionalToken { offset: 715, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 716, length: 12, token: Token::Word(Word::Word("–ø–µ—Ä–∏–æ–¥".to_string())) },
            PositionalToken { offset: 728, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 729, length: 10, token: Token::Word(Word::Word("–º–æ–∂–Ω–æ".to_string())) },
            PositionalToken { offset: 739, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 740, length: 24, token: Token::Word(Word::Word("–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—Ç—å".to_string())) },
            PositionalToken { offset: 764, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 765, length: 2, token: Token::Word(Word::Word("—Å".to_string())) },
            PositionalToken { offset: 767, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 768, length: 24, token: Token::Word(Word::Word("—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é".to_string())) },
            PositionalToken { offset: 792, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 793, length: 30, token: Token::Word(Word::Word("–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ".to_string())) },
            PositionalToken { offset: 823, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 824, length: 16, token: Token::Word(Word::Word("–¥–æ–º–∞—à–Ω–∏–π".to_string())) },
            PositionalToken { offset: 840, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 841, length: 10, token: Token::Word(Word::Word("–æ–±—Ä–∞–∑".to_string())) },
            PositionalToken { offset: 851, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 852, length: 10, token: Token::Word(Word::Word("–∂–∏–∑–Ω–∏".to_string())) },
            PositionalToken { offset: 862, length: 1, token: Token::Special(Special::Punctuation('.')) },
            PositionalToken { offset: 863, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { offset: 864, length: 3, token: Token::BBCode { left: vec![
                ], right: vec![
                ] } },
            ];
        let lib_res = uws.into_tokenizer(TokenizerParams::complex()).collect::<Vec<_>>();
        //print_result(&lib_res); panic!("");
        check_results(&result,&lib_res,uws);
    }*/

    #[test]
    fn html() {
        let uws = "<div class=\"article article_view \" id=\"article_view_-113039156_9551\" data-article-url=\"/@chaibuket-o-chem-ne-zabyt-25-noyabrya\" data-audio-context=\"article:-113039156_9551\"><h1  class=\"article_decoration_first article_decoration_last\" >–î–µ–Ω—å –ú–∞–º—ã </h1><p  class=\"article_decoration_first article_decoration_last\" >–î–µ–Ω—å, –∫–æ–≥–¥–∞ –ø–æ–∑–¥—Ä–∞–≤–ª—è—é—Ç –º–∞–º, –±–∞–±—É—à–µ–∫, —Å–µ—Å—Ç–µ—Ä –∏ –∂—ë–Ω ‚Äî —ç—Ç–æ –≤—Å–µ–º–∏—Ä–Ω—ã–π –ø—Ä–∞–∑–¥–Ω–∏–∫, –Ω–∞–∑—ã–≤–∞–µ–º—ã–π ¬´–î–µ–Ω—å –ú–∞–º—ã¬ª. –í –Ω–∞—Å—Ç–æ—è—â–µ–µ –≤—Ä–µ–º—è –µ–≥–æ –æ—Ç–º–µ—á–∞—é—Ç –ø–æ—á—Ç–∏ –≤ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–µ, –ø—Ä–æ—Å—Ç–æ –≤–µ–∑–¥–µ —Ä–∞–∑–Ω—ã–µ –¥–∞—Ç—ã –∏ —Å–ø–æ—Å–æ–±—ã –ø—Ä–∞–∑–¥–Ω–æ–≤–∞–Ω–∏—è. </p><h3  class=\"article_decoration_first article_decoration_last\" ><span class='article_anchor_title'>\n  <span class='article_anchor_button' id='pochemu-my-ego-prazdnuem'></span>\n  <span class='article_anchor_fsymbol'>–ü</span>\n</span>–ü–û–ß–ï–ú–£ –ú–´ –ï–ì–û –ü–†–ê–ó–î–ù–£–ï–ú</h3><p  class=\"article_decoration_first article_decoration_last article_decoration_before\" >–í 1987 –≥–æ–¥—É –∫–æ–º–∏—Ç–µ—Ç –≥–æ—Å–¥—É–º—ã –ø–æ –¥–µ–ª–∞–º –∂–µ–Ω—â–∏–Ω, —Å–µ–º—å–∏ –∏ –º–æ–ª–æ–¥–µ–∂–∏ –≤—ã—Å—Ç—É–ø–∏–ª —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º —É—á—Ä–µ–¥–∏—Ç—å ¬´–î–µ–Ω—å –º–∞–º—ã¬ª, –∞ —Å–∞–º –ø—Ä–∏–∫–∞–∑ –±—ã–ª –ø–æ–¥–ø–∏—Å–∞–Ω —É–∂–µ 30 —è–Ω–≤–∞—Ä—è 1988 –≥–æ–¥–∞ –ë–æ—Ä–∏—Å–æ–º –ï–ª—å—Ü–∏–Ω—ã–º. –ë—ã–ª–æ —Ä–µ—à–µ–Ω–æ, —á—Ç–æ –µ–∂–µ–≥–æ–¥–Ω–æ –≤ –†–æ—Å—Å–∏–∏ –ø—Ä–∞–∑–¥–Ω–µ—Å—Ç–≤–æ –¥–Ω—è –º–∞–º—ã –±—É–¥–µ—Ç –≤—ã–ø–∞–¥–∞—Ç—å –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–µ –≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ –Ω–æ—è–±—Ä—è. </p><figure data-type=\"101\" data-mode=\"\"  class=\"article_decoration_first article_decoration_last\" >\n  <div class=\"article_figure_content\" style=\"width: 1125px\">\n    <div class=\"article_figure_sizer_content\"><div class=\"article_object_sizer_wrap\" data-sizes=\"[{&quot;s&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c0ffd/pcNJaBH3NDo.jpg&quot;,75,50],&quot;m&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c0ffe/ozCLs2kHtRY.jpg&quot;,130,87],&quot;x&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c0fff/E4KtTNDydzE.jpg&quot;,604,403],&quot;y&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c1000/1nLxpYKavzU.jpg&quot;,807,538],&quot;z&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c1001/IgEODe90yEk.jpg&quot;,1125,750],&quot;o&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c1002/01faNwVZ2_E.jpg&quot;,130,87],&quot;p&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c1003/baDFzbdRP2s.jpg&quot;,200,133],&quot;q&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c1004/CY4khI6KJKA.jpg&quot;,320,213],&quot;r&quot;:[&quot;https://pp.userapi.com/c849128/v849128704/c1005/NOvAJ6-VltY.jpg&quot;,510,340]}]\">\n  <img class=\"article_object_sizer_inner article_object_photo__image_blur\" src=\"https://pp.userapi.com/c849128/v849128704/c0ffd/pcNJaBH3NDo.jpg\" data-baseurl=\"\"/>\n  \n</div></div>\n    <div class=\"article_figure_sizer\" style=\"padding-bottom: 66.666666666667%\"></div>";
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 236,
                length: 8,
                token: Token::Word(Word::Word("–î–µ–Ω—å".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 244,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 245,
                length: 8,
                token: Token::Word(Word::Word("–ú–∞–º—ã".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 253,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 321,
                length: 8,
                token: Token::Word(Word::Word("–î–µ–Ω—å".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 329,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 330,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 331,
                length: 10,
                token: Token::Word(Word::Word("–∫–æ–≥–¥–∞".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 341,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 342,
                length: 22,
                token: Token::Word(Word::Word("–ø–æ–∑–¥—Ä–∞–≤–ª—è—é—Ç".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 364,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 365,
                length: 6,
                token: Token::Word(Word::Word("–º–∞–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 371,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 372,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 373,
                length: 14,
                token: Token::Word(Word::Word("–±–∞–±—É—à–µ–∫".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 387,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 388,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 389,
                length: 12,
                token: Token::Word(Word::Word("—Å–µ—Å—Ç–µ—Ä".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 401,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 402,
                length: 2,
                token: Token::Word(Word::Word("–∏".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 404,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 405,
                length: 6,
                token: Token::Word(Word::Word("–∂—ë–Ω".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 411,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 412,
                length: 3,
                token: Token::Special(Special::Punctuation('‚Äî')),
            },
            PositionalToken {
                source: uws,
                offset: 415,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 416,
                length: 6,
                token: Token::Word(Word::Word("—ç—Ç–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 422,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 423,
                length: 18,
                token: Token::Word(Word::Word("–≤—Å–µ–º–∏—Ä–Ω—ã–π".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 441,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 442,
                length: 16,
                token: Token::Word(Word::Word("–ø—Ä–∞–∑–¥–Ω–∏–∫".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 458,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 459,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 460,
                length: 20,
                token: Token::Word(Word::Word("–Ω–∞–∑—ã–≤–∞–µ–º—ã–π".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 480,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 481,
                length: 2,
                token: Token::Special(Special::Punctuation('¬´')),
            },
            PositionalToken {
                source: uws,
                offset: 483,
                length: 8,
                token: Token::Word(Word::Word("–î–µ–Ω—å".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 491,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 492,
                length: 8,
                token: Token::Word(Word::Word("–ú–∞–º—ã".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 500,
                length: 2,
                token: Token::Special(Special::Punctuation('¬ª')),
            },
            PositionalToken {
                source: uws,
                offset: 502,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 503,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 504,
                length: 2,
                token: Token::Word(Word::Word("–í".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 506,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 507,
                length: 18,
                token: Token::Word(Word::Word("–Ω–∞—Å—Ç–æ—è—â–µ–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 525,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 526,
                length: 10,
                token: Token::Word(Word::Word("–≤—Ä–µ–º—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 536,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 537,
                length: 6,
                token: Token::Word(Word::Word("–µ–≥–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 543,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 544,
                length: 16,
                token: Token::Word(Word::Word("–æ—Ç–º–µ—á–∞—é—Ç".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 560,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 561,
                length: 10,
                token: Token::Word(Word::Word("–ø–æ—á—Ç–∏".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 571,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 572,
                length: 2,
                token: Token::Word(Word::Word("–≤".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 574,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 575,
                length: 12,
                token: Token::Word(Word::Word("–∫–∞–∂–¥–æ–π".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 587,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 588,
                length: 12,
                token: Token::Word(Word::Word("—Å—Ç—Ä–∞–Ω–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 600,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 601,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 602,
                length: 12,
                token: Token::Word(Word::Word("–ø—Ä–æ—Å—Ç–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 614,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 615,
                length: 10,
                token: Token::Word(Word::Word("–≤–µ–∑–¥–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 625,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 626,
                length: 12,
                token: Token::Word(Word::Word("—Ä–∞–∑–Ω—ã–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 638,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 639,
                length: 8,
                token: Token::Word(Word::Word("–¥–∞—Ç—ã".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 647,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 648,
                length: 2,
                token: Token::Word(Word::Word("–∏".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 650,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 651,
                length: 14,
                token: Token::Word(Word::Word("—Å–ø–æ—Å–æ–±—ã".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 665,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 666,
                length: 24,
                token: Token::Word(Word::Word("–ø—Ä–∞–∑–¥–Ω–æ–≤–∞–Ω–∏—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 690,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 691,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 794,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 795,
                length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 870,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 871,
                length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 910,
                length: 2,
                token: Token::Word(Word::Word("–ü".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 919,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 927,
                length: 12,
                token: Token::Word(Word::Word("–ü–û–ß–ï–ú–£".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 939,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 940,
                length: 4,
                token: Token::Word(Word::Word("–ú–´".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 944,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 945,
                length: 6,
                token: Token::Word(Word::Word("–ï–ì–û".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 951,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 952,
                length: 18,
                token: Token::Word(Word::Word("–ü–†–ê–ó–î–ù–£–ï–ú".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1063,
                length: 2,
                token: Token::Word(Word::Word("–í".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1065,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1066,
                length: 4,
                token: Token::Word(Word::Number(Number::Integer(1987))),
            },
            PositionalToken {
                source: uws,
                offset: 1070,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1071,
                length: 8,
                token: Token::Word(Word::Word("–≥–æ–¥—É".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1079,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1080,
                length: 14,
                token: Token::Word(Word::Word("–∫–æ–º–∏—Ç–µ—Ç".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1094,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1095,
                length: 14,
                token: Token::Word(Word::Word("–≥–æ—Å–¥—É–º—ã".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1109,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1110,
                length: 4,
                token: Token::Word(Word::Word("–ø–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1114,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1115,
                length: 10,
                token: Token::Word(Word::Word("–¥–µ–ª–∞–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1125,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1126,
                length: 12,
                token: Token::Word(Word::Word("–∂–µ–Ω—â–∏–Ω".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1138,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 1139,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1140,
                length: 10,
                token: Token::Word(Word::Word("—Å–µ–º—å–∏".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1150,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1151,
                length: 2,
                token: Token::Word(Word::Word("–∏".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1153,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1154,
                length: 16,
                token: Token::Word(Word::Word("–º–æ–ª–æ–¥–µ–∂–∏".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1170,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1171,
                length: 16,
                token: Token::Word(Word::Word("–≤—ã—Å—Ç—É–ø–∏–ª".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1187,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1188,
                length: 2,
                token: Token::Word(Word::Word("—Å".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1190,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1191,
                length: 24,
                token: Token::Word(Word::Word("–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1215,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1216,
                length: 16,
                token: Token::Word(Word::Word("—É—á—Ä–µ–¥–∏—Ç—å".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1232,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1233,
                length: 2,
                token: Token::Special(Special::Punctuation('¬´')),
            },
            PositionalToken {
                source: uws,
                offset: 1235,
                length: 8,
                token: Token::Word(Word::Word("–î–µ–Ω—å".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1243,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1244,
                length: 8,
                token: Token::Word(Word::Word("–º–∞–º—ã".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1252,
                length: 2,
                token: Token::Special(Special::Punctuation('¬ª')),
            },
            PositionalToken {
                source: uws,
                offset: 1254,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 1255,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1256,
                length: 2,
                token: Token::Word(Word::Word("–∞".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1258,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1259,
                length: 6,
                token: Token::Word(Word::Word("—Å–∞–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1265,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1266,
                length: 12,
                token: Token::Word(Word::Word("–ø—Ä–∏–∫–∞–∑".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1278,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1279,
                length: 6,
                token: Token::Word(Word::Word("–±—ã–ª".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1285,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1286,
                length: 16,
                token: Token::Word(Word::Word("–ø–æ–¥–ø–∏—Å–∞–Ω".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1302,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1303,
                length: 6,
                token: Token::Word(Word::Word("—É–∂–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1309,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1310,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(30))),
            },
            PositionalToken {
                source: uws,
                offset: 1312,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1313,
                length: 12,
                token: Token::Word(Word::Word("—è–Ω–≤–∞—Ä—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1325,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1326,
                length: 4,
                token: Token::Word(Word::Number(Number::Integer(1988))),
            },
            PositionalToken {
                source: uws,
                offset: 1330,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1331,
                length: 8,
                token: Token::Word(Word::Word("–≥–æ–¥–∞".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1339,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1340,
                length: 14,
                token: Token::Word(Word::Word("–ë–æ—Ä–∏—Å–æ–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1354,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1355,
                length: 16,
                token: Token::Word(Word::Word("–ï–ª—å—Ü–∏–Ω—ã–º".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1371,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 1372,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1373,
                length: 8,
                token: Token::Word(Word::Word("–ë—ã–ª–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1381,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1382,
                length: 12,
                token: Token::Word(Word::Word("—Ä–µ—à–µ–Ω–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1394,
                length: 1,
                token: Token::Special(Special::Punctuation(',')),
            },
            PositionalToken {
                source: uws,
                offset: 1395,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1396,
                length: 6,
                token: Token::Word(Word::Word("—á—Ç–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1402,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1403,
                length: 16,
                token: Token::Word(Word::Word("–µ–∂–µ–≥–æ–¥–Ω–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1419,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1420,
                length: 2,
                token: Token::Word(Word::Word("–≤".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1422,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1423,
                length: 12,
                token: Token::Word(Word::Word("–†–æ—Å—Å–∏–∏".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1435,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1436,
                length: 22,
                token: Token::Word(Word::Word("–ø—Ä–∞–∑–¥–Ω–µ—Å—Ç–≤–æ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1458,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1459,
                length: 6,
                token: Token::Word(Word::Word("–¥–Ω—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1465,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1466,
                length: 8,
                token: Token::Word(Word::Word("–º–∞–º—ã".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1474,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1475,
                length: 10,
                token: Token::Word(Word::Word("–±—É–¥–µ—Ç".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1485,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1486,
                length: 16,
                token: Token::Word(Word::Word("–≤—ã–ø–∞–¥–∞—Ç—å".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1502,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1503,
                length: 4,
                token: Token::Word(Word::Word("–Ω–∞".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1507,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1508,
                length: 18,
                token: Token::Word(Word::Word("–ø–æ—Å–ª–µ–¥–Ω–µ–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1526,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1527,
                length: 22,
                token: Token::Word(Word::Word("–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1549,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1550,
                length: 12,
                token: Token::Word(Word::Word("–Ω–æ—è–±—Ä—è".to_string())),
            },
            PositionalToken {
                source: uws,
                offset: 1562,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 1563,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1664,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 1665,
                length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 1725,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 1726,
                length: 4,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 2725,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 2726,
                length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 2888,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 2889,
                length: 2,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 2891,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 2904,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Newline)),
            },
            PositionalToken {
                source: uws,
                offset: 2905,
                length: 4,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
        ];

        let text = Text::new({
            uws.into_source()
                .pipe(tagger::Builder::new().create().into_breaker())
                .pipe(entities::Builder::new().create().into_piped())
                .into_separator()
        })
        .unwrap();

        let lib_res = text
            .into_tokenizer(TokenizerParams::v1())
            .filter_map(|tt| tt.into_original_token_1())
            .collect::<Vec<_>>();

        check_results(&result, &lib_res, uws);
    }

    /*#[test]
    fn vk_bbcode() {
        let uws = "[club113623432|üíúüíúüíú - –¥–ª—è –¥–µ–≤—É—à–µ–∫] \n[club113623432|üíõüíõüíõ - –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ–∫]";
        let result = vec![
            PositionalToken { offset: 0, length: 52, token: Token::BBCode { left: vec![
                PositionalToken { offset: 1, length: 13, token: Token::Word(Word::Numerical(Numerical::Alphanumeric("club113623432".to_string()))) },
                ], right: vec![
                PositionalToken { offset: 15, length: 4, token: Token::Word(Word::Emoji("purple_heart")) },
                PositionalToken { offset: 19, length: 4, token: Token::Word(Word::Emoji("purple_heart")) },
                PositionalToken { offset: 23, length: 4, token: Token::Word(Word::Emoji("purple_heart")) },
                PositionalToken { offset: 27, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
                PositionalToken { offset: 28, length: 1, token: Token::Special(Special::Punctuation('-')) },
                PositionalToken { offset: 29, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
                PositionalToken { offset: 30, length: 6, token: Token::Word(Word::Word("–¥–ª—è".to_string())) },
                PositionalToken { offset: 36, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
                PositionalToken { offset: 37, length: 14, token: Token::Word(Word::Word("–¥–µ–≤—É—à–µ–∫".to_string())) },
                ] } },
            PositionalToken { offset: 52, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
            PositionalToken { offset: 53, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            PositionalToken { offset: 54, length: 58, token: Token::BBCode { left: vec![
                PositionalToken { offset: 55, length: 13, token: Token::Word(Word::Numerical(Numerical::Alphanumeric("club113623432".to_string()))) },
                ], right: vec![
                PositionalToken { offset: 69, length: 4, token: Token::Word(Word::Emoji("yellow_heart")) },
                PositionalToken { offset: 73, length: 4, token: Token::Word(Word::Emoji("yellow_heart")) },
                PositionalToken { offset: 77, length: 4, token: Token::Word(Word::Emoji("yellow_heart")) },
                PositionalToken { offset: 81, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
                PositionalToken { offset: 82, length: 1, token: Token::Special(Special::Punctuation('-')) },
                PositionalToken { offset: 83, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
                PositionalToken { offset: 84, length: 6, token: Token::Word(Word::Word("–¥–ª—è".to_string())) },
                PositionalToken { offset: 90, length: 1, token: Token::Special(Special::Separator(Separator::Space)) },
                PositionalToken { offset: 91, length: 20, token: Token::Word(Word::Word("—Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ–∫".to_string())) },
                ] } },
            ];
        let lib_res = uws.into_tokenizer(TokenizerParams::complex()).collect::<Vec<_>>();
        //print_result(&lib_res); panic!("");
        check_results(&result,&lib_res,uws);
    }*/

    /*#[test]
    fn text_href_and_html () {
        let uws = "https://youtu.be/dQErLQZw3qA</a></p><figure data-type=\"102\" data-mode=\"\"  class=\"article_decoration_first article_decoration_last\" >\n";
        let result =  vec![
            PositionalToken { offset: 0, length: 28, token: Token::Struct(Struct::Url("https://youtu.be/dQErLQZw3qA".to_string())) },
            PositionalToken { offset: 132, length: 1, token: Token::Special(Special::Separator(Separator::Newline)) },
            ];
        let lib_res = uws.into_tokenizer(TokenizerParams::v1()).unwrap().collect::<Vec<_>>();
        check_results(&result,&lib_res,uws);
        //print_result(&lib_res); panic!("")
    }*/

    #[test]
    fn numerical_no_split() {
        let uws = "12.02.18 31.28.34 23.11.2018 123.568.365.234.578 127.0.0.1 1st 1–∫–≥ 123123–∞—Ñ—ã–≤–∞—ã–≤ 12321—Ñ–≤–∞—Ñ—ã–æ–≤234–≤—ã–∞–ª—Ñ–æ 12_123_343.4234_4234";
        let lib_res = uws.into_tokenizer(Default::default()).collect::<Vec<_>>();
        //print_result(&lib_res); panic!("");
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 8,
                token: Token::Word(Word::Numerical(Numerical::DotSeparated(
                    "12.02.18".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 8,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 8,
                token: Token::Word(Word::Numerical(Numerical::DotSeparated(
                    "31.28.34".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 17,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 18,
                length: 10,
                token: Token::Word(Word::Numerical(Numerical::DotSeparated(
                    "23.11.2018".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 28,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 29,
                length: 19,
                token: Token::Word(Word::Numerical(Numerical::DotSeparated(
                    "123.568.365.234.578".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 48,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 49,
                length: 9,
                token: Token::Word(Word::Numerical(Numerical::DotSeparated(
                    "127.0.0.1".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 58,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 59,
                length: 3,
                token: Token::Word(Word::Numerical(Numerical::Measures("1st".to_string()))),
            },
            PositionalToken {
                source: uws,
                offset: 62,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 63,
                length: 5,
                token: Token::Word(Word::Numerical(Numerical::Measures("1–∫–≥".to_string()))),
            },
            PositionalToken {
                source: uws,
                offset: 68,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 69,
                length: 20,
                token: Token::Word(Word::Numerical(Numerical::Measures(
                    "123123–∞—Ñ—ã–≤–∞—ã–≤".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 89,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 90,
                length: 34,
                token: Token::Word(Word::Numerical(Numerical::Alphanumeric(
                    "12321—Ñ–≤–∞—Ñ—ã–æ–≤234–≤—ã–∞–ª—Ñ–æ".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 124,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 125,
                length: 20,
                token: Token::Word(Word::Numerical(Numerical::Alphanumeric(
                    "12_123_343.4234_4234".to_string(),
                ))),
            },
        ];
        check_results(&result, &lib_res, uws);
    }

    #[test]
    fn numerical_default() {
        let uws = "12.02.18 31.28.34 23.11.2018 123.568.365.234.578 127.0.0.1 1st 1–∫–≥ 123123–∞—Ñ—ã–≤–∞—ã–≤ 12321—Ñ–≤–∞—Ñ—ã–æ–≤234–≤—ã–∞–ª—Ñ–æ 12_123_343.4234_4234";
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        //print_result(&lib_res); panic!("");
        let result = vec![
            PositionalToken {
                source: uws,
                offset: 0,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(12))),
            },
            PositionalToken {
                source: uws,
                offset: 2,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 3,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(2))),
            },
            PositionalToken {
                source: uws,
                offset: 5,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 6,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(18))),
            },
            PositionalToken {
                source: uws,
                offset: 8,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 9,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(31))),
            },
            PositionalToken {
                source: uws,
                offset: 11,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 12,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(28))),
            },
            PositionalToken {
                source: uws,
                offset: 14,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 15,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(34))),
            },
            PositionalToken {
                source: uws,
                offset: 17,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 18,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(23))),
            },
            PositionalToken {
                source: uws,
                offset: 20,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 21,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(11))),
            },
            PositionalToken {
                source: uws,
                offset: 23,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 24,
                length: 4,
                token: Token::Word(Word::Number(Number::Integer(2018))),
            },
            PositionalToken {
                source: uws,
                offset: 28,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 29,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(123))),
            },
            PositionalToken {
                source: uws,
                offset: 32,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 33,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(568))),
            },
            PositionalToken {
                source: uws,
                offset: 36,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 37,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(365))),
            },
            PositionalToken {
                source: uws,
                offset: 40,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 41,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(234))),
            },
            PositionalToken {
                source: uws,
                offset: 44,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 45,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(578))),
            },
            PositionalToken {
                source: uws,
                offset: 48,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 49,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(127))),
            },
            PositionalToken {
                source: uws,
                offset: 52,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 53,
                length: 1,
                token: Token::Word(Word::Number(Number::Integer(0))),
            },
            PositionalToken {
                source: uws,
                offset: 54,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 55,
                length: 1,
                token: Token::Word(Word::Number(Number::Integer(0))),
            },
            PositionalToken {
                source: uws,
                offset: 56,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 57,
                length: 1,
                token: Token::Word(Word::Number(Number::Integer(1))),
            },
            PositionalToken {
                source: uws,
                offset: 58,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 59,
                length: 3,
                token: Token::Word(Word::Numerical(Numerical::Measures("1st".to_string()))),
            },
            PositionalToken {
                source: uws,
                offset: 62,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 63,
                length: 5,
                token: Token::Word(Word::Numerical(Numerical::Measures("1–∫–≥".to_string()))),
            },
            PositionalToken {
                source: uws,
                offset: 68,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 69,
                length: 20,
                token: Token::Word(Word::Numerical(Numerical::Measures(
                    "123123–∞—Ñ—ã–≤–∞—ã–≤".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 89,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 90,
                length: 34,
                token: Token::Word(Word::Numerical(Numerical::Alphanumeric(
                    "12321—Ñ–≤–∞—Ñ—ã–æ–≤234–≤—ã–∞–ª—Ñ–æ".to_string(),
                ))),
            },
            PositionalToken {
                source: uws,
                offset: 124,
                length: 1,
                token: Token::Special(Special::Separator(Separator::Space)),
            },
            PositionalToken {
                source: uws,
                offset: 125,
                length: 2,
                token: Token::Word(Word::Number(Number::Integer(12))),
            },
            PositionalToken {
                source: uws,
                offset: 127,
                length: 1,
                token: Token::Special(Special::Punctuation('_')),
            },
            PositionalToken {
                source: uws,
                offset: 128,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(123))),
            },
            PositionalToken {
                source: uws,
                offset: 131,
                length: 1,
                token: Token::Special(Special::Punctuation('_')),
            },
            PositionalToken {
                source: uws,
                offset: 132,
                length: 3,
                token: Token::Word(Word::Number(Number::Integer(343))),
            },
            PositionalToken {
                source: uws,
                offset: 135,
                length: 1,
                token: Token::Special(Special::Punctuation('.')),
            },
            PositionalToken {
                source: uws,
                offset: 136,
                length: 4,
                token: Token::Word(Word::Number(Number::Integer(4234))),
            },
            PositionalToken {
                source: uws,
                offset: 140,
                length: 1,
                token: Token::Special(Special::Punctuation('_')),
            },
            PositionalToken {
                source: uws,
                offset: 141,
                length: 4,
                token: Token::Word(Word::Number(Number::Integer(4234))),
            },
        ];
        check_results(&result, &lib_res, uws);
    }

    /*#[test]
        fn new_test() {
            let uws = "";
            let lib_res = uws.into_tokenizer(TokenizerParams::v1()).unwrap().collect::<Vec<_>>();
            print_result(&lib_res); panic!("");
            let result = vec![];
            check_results(&result,&lib_res,uws);

    }*/

    /* Language tests */

    enum Lang {
        Zho,
        Jpn,
        Kor,
        Ara,
        Ell,
    }

    #[test]
    fn test_lang_zho() {
        let (uws, result) = get_lang_test(Lang::Zho);
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, &uws);
    }

    #[test]
    fn test_lang_jpn() {
        let (uws, result) = get_lang_test(Lang::Jpn);
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, &uws);
    }

    #[test]
    fn test_lang_kor() {
        let (uws, result) = get_lang_test(Lang::Kor);
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, &uws);
    }

    #[test]
    fn test_lang_ara() {
        let (uws, result) = get_lang_test(Lang::Ara);
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, &uws);
    }

    #[test]
    fn test_lang_ell() {
        let (uws, result) = get_lang_test(Lang::Ell);
        let lib_res = uws
            .into_tokenizer(TokenizerParams::v1())
            .collect::<Vec<_>>();
        check_results(&result, &lib_res, &uws);
    }

    fn get_lang_test(lng: Lang) -> (String, Vec<PositionalToken>) {
        let uws = match lng {
            Lang::Zho => "ÁæéÂõΩÁîµËßÜËøûÁª≠Ââß„ÄäË∂Ö‰∫∫Ââç‰º†„ÄãÁöÑÁ¨¨‰∏ÄÈõÜ„ÄäËØïÊí≠ÈõÜ„Äã‰∫é2001Âπ¥10Êúà16Êó•Âú®ÈõªË¶ñÁ∂≤È¶ñÊí≠ÔºåÂâßÈõÜ‰∏ªÂàõ‰∫∫ÈòøÂ∞îÂºóÈõ∑Âæ∑¬∑È´òÂ§´ÂíåËøàÂ∞îÊñØ¬∑Á±≥ÂãíÁ∑®ÂäáÔºåÂ§ßÂç´¬∑Âä™ÁâπÂ∞îÊâßÂØº„ÄÇËøô‰∏ÄËØïÊí≠È¶ñÊ¨°ÂêëËßÇ‰ºóÂºïËçê‰∫ÜÂÖãÊãâÂÖã¬∑ËÇØÁâπ‰∏ÄËßíÔºå‰ªñÊòØ‰ΩçÊã•ÊúâË∂ÖËÉΩÂäõÁöÑÂ§ñÊòüÂ≠§ÂÑøÔºå‰∏éÂÆ∂‰∫∫ÂíåÊúãÂèã‰∏ÄËµ∑Âú®Â†™Ëñ©ÊñØÂ∑ûËôöÊûÑÂ∞èÈïáÊñØËé´Áª¥Â∞îÁîüÊ¥ª„ÄÇÂú®Ëøô‰∏ÄÈõÜÈáåÔºåËÇØÁâπÈ¶ñÂ∫¶ÂæóÁü•Ëá™Â∑±ÁöÑÊù•ÂéÜÔºåÂêåÊó∂ËøòÈúÄË¶ÅÈòªÊ≠¢‰∏Ä‰ΩçÂ≠¶ÁîüËØïÂõæÊùÄÊ≠ªÈïá‰∏äÈ´ò‰∏≠Â§öÂêçÂ≠¶ÁîüÁöÑÊä•Â§ç‰πã‰∏æ„ÄÇÊú¨ÈõÜËäÇÁõÆÈáåÂºïÂÖ•‰∫ÜÂ§ö‰∏™‰πãÂêéÂ∞ÜË¥ØÁ©øÂÖ®Â≠£ÁîöËá≥Êï¥ÈÉ®ÂâßÈõÜÁöÑ‰∏ªÈ¢òÂÖÉÁ¥†Ôºå‰æãÂ¶ÇÂá†‰Ωç‰∏ªË¶ÅËßíËâ≤‰πãÈó¥ÁöÑ‰∏âËßíÊÅãÊÉÖ„ÄÇÁîµËßÜÂâßÂú®Âä†ÊãøÂ§ßÊ∫´Âì•ËèØÂèñÊôØÔºåÊó®Âú®ÈÄâÁî®ÂÖ∂‚ÄúÁæéÂõΩ‰∏≠‰∫ßÈò∂Á∫ß‚ÄùÊôØËßÇÔºå‰∏ªÂàõ‰∫∫Ëä±‰∫Ü5‰∏™ÊúàÁöÑÊó∂Èó¥‰∏ìÈó®Áî®‰∫é‰∏∫‰∏ªËßíÁâ©Ëâ≤ÂêàÈÄÇÁöÑÊºîÂëò„ÄÇËØïÊí≠ÈõÜÂú®ÊâÄÊúâÊºîÂëòÈÄâÂ•Ω4Â§©ÂêéÊ≠£ÂºèÂºÄÊãç„ÄÇÁî±‰∫éÊó∂Èó¥‰∏äÁöÑÈôêÂà∂ÔºåÂâßÁªÑÊó†Ê≥ïÊê≠Âª∫Â•ΩÂÆû‰ΩìÂ§ñÊôØÔºåÂõ†Ê≠§Âè™ËÉΩ‰ΩøÁî®ËÆ°ÁÆóÊú∫ÁªòÂõæÊäÄÊúØÂ∞ÜÊï∞Â≠óÂåñÁöÑÂ§ñÊôØÊèíÂÖ•Âà∞ÈïúÂ§¥‰∏≠„ÄÇËäÇÁõÆ‰∏ÄÁªè‰∏äÊò†Â∞±ÊâìÁ†¥‰∫ÜÁîµËßÜÁΩëÁöÑÂ§öÈ°πÊî∂ËßÜÁ∫™ÂΩïÔºåÂπ∂‰∏îËé∑Âæó‰∫ÜËØÑËÆ∫ÂëòÁöÑÊôÆÈÅçÂ•ΩËØÑÂíåÂ§ö‰∏™Â•ñÈ°πÊèêÂêçÔºåÂπ∂Âú®ÂÖ∂‰∏≠‰∏§È°π‰∏äËÉúÂá∫",
            Lang::Kor =>  "ÌîåÎ†àÏù¥Ïä§ÌÖåÏù¥ÏÖò ÏùÄ ÏÜåÎãà Ïª¥Ìì®ÌÑ∞ ÏóîÌÑ∞ÌÖåÏù∏Î®ºÌä∏Í∞Ä Í∞úÎ∞úÌïú ÏÑ∏ Î≤àÏß∏ Í∞ÄÏ†ïÏö© Í≤åÏûÑÍ∏∞Ïù¥Îã§. ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏Ïùò ÏóëÏä§Î∞ïÏä§ 360, ÎãåÌÖêÎèÑÏùò WiiÏôÄ Í≤ΩÏüÅÌïòÍ≥† ÏûàÎã§. Ïù¥Ï†Ñ Ï†úÌíàÏóêÏÑú Ïò®ÎùºÏù∏ ÌîåÎ†àÏù¥ Í∏∞Îä•ÏùÑ ÎπÑÎîîÏò§ Í≤åÏûÑ Í∞úÎ∞úÏÇ¨Ïóê Ï†ÑÏ†ÅÏúºÎ°ú ÏùòÏ°¥ÌïòÎçò Í≤ÉÍ≥º Îã¨Î¶¨ ÌÜµÌï© Ïò®ÎùºÏù∏ Í≤åÏûÑ ÏÑúÎπÑÏä§Ïù∏ ÌîåÎ†àÏù¥Ïä§ÌÖåÏù¥ÏÖò ÎÑ§Ìä∏ÏõåÌÅ¨ ÏÑúÎπÑÏä§Î•º Î∞úÎß§ÏôÄ Ìï®Íªò ÏãúÏûëÌï¥ Ï†úÍ≥µÌïòÍ≥† ÏûàÏúºÎ©∞, ÌÉÑÌÉÑÌïú Î©ÄÌã∞ÎØ∏ÎîîÏñ¥ Ïû¨ÏÉù Í∏∞Îä•, ÌîåÎ†àÏù¥Ïä§ÌÖåÏù¥ÏÖò Ìè¨ÌÑ∞Î∏îÍ≥ºÏùò Ïó∞Í≤∞, Í≥†ÌôîÏßà Í¥ëÌïô ÎîîÏä§ÌÅ¨ Ìè¨Îß∑Ïù∏ Î∏îÎ£®Î†àÏù¥ ÎîîÏä§ÌÅ¨ Ïû¨ÏÉù Í∏∞Îä• Îì±Ïùò Í∏∞Îä•ÏùÑ Í∞ñÏ∂îÍ≥† ÏûàÎã§. 2006ÎÖÑ 11Ïõî 11ÏùºÏóê ÏùºÎ≥∏ÏóêÏÑú Ï≤òÏùåÏúºÎ°ú Ï∂úÏãúÌñàÏúºÎ©∞, 11Ïõî 17ÏùºÏóêÎäî Î∂ÅÎØ∏ ÏßÄÏó≠, 2007ÎÖÑ 3Ïõî 23ÏùºÏóêÎäî Ïú†ÎüΩÍ≥º Ïò§ÏÑ∏ÏïÑÎãàÏïÑ ÏßÄÏó≠ÏóêÏÑú, ÎåÄÌïúÎØºÍµ≠Ïùò Í≤ΩÏö∞ 6Ïõî 5ÏùºÎ∂ÄÌÑ∞ ÏùºÏ£ºÏùºÍ∞Ñ ÏòàÏïΩÌåêÎß§Î•º Ïã§ÏãúÌï¥, Îß§Ïùº Ï§ÄÎπÑÌïú ÏàòÎüâÏù¥ ÎèôÏù¥ ÎÇòÎäî Îì± ÎßéÏùÄ Í¥ÄÏã¨ÏùÑ Î∞õÏïòÏúºÎ©∞ 6Ïõî 16ÏùºÏóê Ï†ïÏãù Ï∂úÏãú ÌñâÏÇ¨Î•º Ïó¥ÏóàÎã§",
            Lang::Jpn => "ÁÜäÈáé‰∏âÂ±±Êú¨È°òÊâÄ„ÅØ„ÄÅ15‰∏ñÁ¥ÄÊú´‰ª•Èôç„Å´„Åä„Åë„ÇãÁÜäÈáé‰∏âÂ±±ÔºàÁÜäÈáéÊú¨ÂÆÆ„ÄÅÁÜäÈáéÊñ∞ÂÆÆ„ÄÅÁÜäÈáéÈÇ£Êô∫Ôºâ„ÅÆÈÄ†Âñ∂„Éª‰øÆÈÄ†„ÅÆ„Åü„ÇÅ„ÅÆÂãßÈÄ≤„ÇíÊãÖ„Å£„ÅüÁµÑÁπî„ÅÆÁ∑èÁß∞„ÄÇ ÁÜäÈáé‰∏âÂ±±„ÇíÂê´„ÇÅ„Å¶„ÄÅÊó•Êú¨„Å´„Åä„Åë„ÇãÂè§‰ª£„Åã„Çâ‰∏≠‰∏ñÂâçÂçä„Å´„Åã„Åë„Å¶„ÅÆÂØ∫Á§æ„ÅÆÈÄ†Âñ∂„ÅØ„ÄÅÂØ∫Á§æÈ†òÁµåÂñ∂„ÅÆ„Çà„ÅÜ„Å™ÊÅíÂ∏∏ÁöÑË≤°Ê∫ê„ÄÅÂπïÂ∫ú„ÇÑÊúùÂª∑„Å™„Å©„Åã„Çâ„ÅÆ‰∏ÄÊôÇÁöÑ„Å™ÈÄ†Âñ∂ÊñôÊâÄ„ÅÆÂØÑÈÄ≤„ÄÅ„ÅÇ„Çã„ÅÑ„ÅØÂÖ¨Ê®©Âäõ„Åã„Çâ„ÅÆËá®ÊôÇ„ÅÆ‰øùË≠∑„Å´„Çà„Å£„Å¶Ë°å„Çè„Çå„Å¶„ÅÑ„Åü„ÄÇ„Åó„Åã„Åó„Å™„Åå„Çâ„ÄÅÁÜäÈáé‰∏âÂ±±„Åß„ÅØ„ÄÅ„Åì„Çå„Çâ„ÅÆË≤°Ê∫ê„ÅØ„Åô„Åπ„Å¶15‰∏ñÁ¥ÄÂçä„Å∞„Åæ„Åß„Å´ÂÆüÂäπÊÄß„ÇíÂ§±„Å£„Åü",
            Lang::Ara => "ŸÑÿ¥⁄©ÿ±⁄©ÿ¥€å‚ÄåŸáÿß€å ÿ±Ÿàÿ≥‚ÄåŸáÿß€å Ÿàÿßÿ±ŸÜ⁄Ø€å ÿ®Ÿá ÿØÿ±€åÿß€å ÿÆÿ≤ÿ± ŸÖÿ¨ŸÖŸàÿπŸá‚Äåÿß€å ÿßÿ≤ ÿ≠ŸÖŸÑÿßÿ™ ŸÜÿ∏ÿßŸÖ€å ÿØÿ± ÿ®€åŸÜ ÿ≥ÿßŸÑ‚ÄåŸáÿß€å €∏€∂€¥ ÿ™ÿß €±€∞€¥€± ŸÖ€åŸÑÿßÿØ€å ÿ®Ÿá ÿ≥Ÿàÿßÿ≠ŸÑ ÿØÿ±€åÿß€å ÿÆÿ≤ÿ± ÿ®ŸàÿØŸá‚Äåÿßÿ≥ÿ™. ÿ±Ÿàÿ≥‚ÄåŸáÿß€å Ÿàÿßÿ±ŸÜ⁄Ø€å ÿßÿ®ÿ™ÿØÿß ÿØÿ± ŸÇÿ±ŸÜ ŸÜŸáŸÖ ŸÖ€åŸÑÿßÿØ€å ÿ®Ÿá ÿπŸÜŸàÿßŸÜ ÿ®ÿßÿ≤ÿ±⁄ØÿßŸÜÿßŸÜ ŸæŸàÿ≥ÿ™ÿå ÿπÿ≥ŸÑ Ÿà ÿ®ÿ±ÿØŸá ÿØÿ± ÿ≥ÿ±ÿ≤ŸÖ€åŸÜ‚ÄåŸáÿß€å ÿßÿ≥ŸÑÿßŸÖ€å(ÿ≥ÿ±⁄©ŸÑŸÜÿØ) ÿ∏ÿßŸáÿ± ÿ¥ÿØŸÜÿØ. ÿß€åŸÜ ÿ®ÿßÿ≤ÿ±⁄ØÿßŸÜÿßŸÜ ÿØÿ± ŸÖÿ≥€åÿ± ÿ™ÿ¨ÿßÿ±€å ŸàŸÑ⁄Øÿß ÿ®Ÿá ÿÆÿ±€åÿØ Ÿà ŸÅÿ±Ÿàÿ¥ ŸÖ€å‚ÄåŸæÿ±ÿØÿßÿÆÿ™ŸÜÿØ. ŸÜÿÆÿ≥ÿ™€åŸÜ ÿ≠ŸÖŸÑŸáŸî ÿ¢ŸÜÿßŸÜ ÿØÿ± ŸÅÿßÿµŸÑŸá ÿ≥ÿßŸÑ‚ÄåŸáÿß€å €∏€∂€¥ ÿ™ÿß €∏€∏€¥ ŸÖ€åŸÑÿßÿØ€å ÿØÿ± ŸÖŸÇ€åÿßÿ≥€å ⁄©Ÿà⁄Ü⁄© ÿπŸÑ€åŸá ÿπŸÑŸà€åÿßŸÜ ÿ∑ÿ®ÿ±ÿ≥ÿ™ÿßŸÜ ÿ±ÿÆ ÿØÿßÿØ. ŸÜÿÆÿ≥ÿ™€åŸÜ €åŸàÿ±ÿ¥ ÿ®ÿ≤ÿ±⁄Ø ÿ±Ÿàÿ≥‚ÄåŸáÿß ÿØÿ± ÿ≥ÿßŸÑ €π€±€≥ ÿ±ÿÆ ÿØÿßÿØ Ÿà ÿ¢ŸÜÿßŸÜ ÿ®ÿß €µ€∞€∞ ŸÅÿ±ŸàŸÜÿØ ÿØÿ±ÿßÿ≤⁄©ÿ¥ÿ™€å ÿ¥Ÿáÿ± ⁄Øÿ±⁄ØÿßŸÜ Ÿà ÿßÿ∑ÿ±ÿßŸÅ ÿ¢ŸÜ ÿ±ÿß ÿ∫ÿßÿ±ÿ™ ⁄©ÿ±ÿØŸÜÿØ. ÿ¢ŸÜ‚ÄåŸáÿß ÿØÿ± ÿß€åŸÜ ÿ≠ŸÖŸÑŸá ŸÖŸÇÿØÿßÿ±€å ⁄©ÿßŸÑÿß Ÿà ÿ®ÿ±ÿØŸá ÿ±ÿß ÿ®Ÿá ÿ™ÿßÿ±ÿßÿ¨ ÿ®ÿ±ÿØŸÜÿØ Ÿà ÿØÿ± ÿ±ÿßŸá ÿ®ÿßÿ≤⁄Øÿ¥ÿ™ŸÜ ÿ®Ÿá ÿ≥ŸÖÿ™ ÿ¥ŸÖÿßŸÑÿå ÿØÿ± ÿØŸÑÿ™ÿß€å ŸàŸÑ⁄Øÿßÿå ŸÖŸàÿ±ÿØ ÿ≠ŸÖŸÑŸáŸî ÿÆÿ≤ÿ±Ÿáÿß€å ŸÖÿ≥ŸÑŸÖÿßŸÜ ŸÇÿ±ÿßÿ± ⁄Øÿ±ŸÅÿ™ŸÜÿØ Ÿà ÿ®ÿπÿ∂€å ÿßÿ≤ ÿ¢ŸÜÿßŸÜ ŸÖŸàŸÅŸÇ ÿ®Ÿá ŸÅÿ±ÿßÿ± ÿ¥ÿØŸÜÿØÿå ŸàŸÑ€å ÿØÿ± ŸÖ€åÿßŸÜŸáŸî ŸàŸÑ⁄Øÿß ÿ®Ÿá ŸÇÿ™ŸÑ ÿ±ÿ≥€åÿØŸÜÿØ. ÿØŸàŸÖ€åŸÜ Ÿáÿ¨ŸàŸÖ ÿ®ÿ≤ÿ±⁄Ø ÿ±Ÿàÿ≥‚ÄåŸáÿß ÿ®Ÿá ÿØÿ±€åÿß€å ÿÆÿ≤ÿ± ÿØÿ± ÿ≥ÿßŸÑ €π€¥€≥ ÿ®Ÿá ŸàŸÇŸàÿπ Ÿæ€åŸàÿ≥ÿ™. ÿØÿ± ÿß€åŸÜ ÿØŸàÿ±Ÿá ÿß€å⁄ØŸàÿ± €å⁄©ŸÖÿå ÿ≠ÿß⁄©ŸÖ ÿ±Ÿàÿ≥ ⁄©€åŸÅÿå ÿ±Ÿáÿ®ÿ±€å ÿ±Ÿàÿ≥‚ÄåŸáÿß ÿ±ÿß ÿØÿ± ÿØÿ≥ÿ™ ÿØÿßÿ¥ÿ™. ÿ±Ÿàÿ≥‚ÄåŸáÿß Ÿæÿ≥ ÿßÿ≤ ÿ™ŸàÿßŸÅŸÇ ÿ®ÿß ÿØŸàŸÑÿ™ ÿÆÿ≤ÿ±Ÿáÿß ÿ®ÿ±ÿß€å ÿπÿ®Ÿàÿ± ÿßŸÖŸÜ ÿßÿ≤ ŸÖŸÜÿ∑ŸÇŸáÿå ÿ™ÿß ÿ±ŸàÿØ ⁄©Ÿàÿ±ÿß Ÿà ÿßÿπŸÖÿßŸÇ ŸÇŸÅŸÇÿßÿ≤ Ÿæ€åÿ¥ ÿ±ŸÅÿ™ŸÜÿØ Ÿà ÿØÿ± ÿ≥ÿßŸÑ €π€¥€≥ ŸÖŸàŸÅŸÇ ÿ¥ÿØŸÜÿØ ÿ®ŸÜÿØÿ± ÿ®ÿ±ÿØÿπŸáÿå Ÿæÿß€åÿ™ÿÆÿ™ ÿßÿ±ÿßŸÜ (ÿ¨ŸÖŸáŸàÿ±€å ÿ¢ÿ∞ÿ±ÿ®ÿß€åÿ¨ÿßŸÜ ⁄©ŸÜŸàŸÜ€å)ÿå ÿ±ÿß ÿ™ÿµÿ±ŸÅ ⁄©ŸÜŸÜÿØ. ÿ±Ÿàÿ≥‚ÄåŸáÿß ÿØÿ± ÿ¢ŸÜÿ¨ÿß ÿ®Ÿá ŸÖÿØÿ™ ⁄ÜŸÜÿØ ŸÖÿßŸá ŸÖÿßŸÜÿØŸÜÿØ Ÿà ÿ®ÿ≥€åÿßÿ±€å ÿßÿ≤ ÿ≥ÿß⁄©ŸÜÿßŸÜ ÿ¥Ÿáÿ± ÿ±ÿß ⁄©ÿ¥ÿ™ŸÜÿØ Ÿà ÿßÿ≤ ÿ±ÿßŸá ÿ∫ÿßÿ±ÿ™‚Äå⁄Øÿ±€å ÿßŸÖŸàÿßŸÑ€å ÿ±ÿß ÿ®Ÿá ÿ™ÿßÿ±ÿßÿ¨ ÿ®ÿ±ÿØŸÜÿØ. ÿ™ŸÜŸáÿß ÿØŸÑ€åŸÑ ÿ®ÿßÿ≤⁄Øÿ¥ÿ™ ÿ¢ŸÜÿßŸÜ ",
            Lang::Ell => "Œ§Œø Œ†œÅœåŒ≥œÅŒ±ŒºŒºŒ± œÖŒªŒøœÄŒøŒπŒµŒØœÑŒ±Œπ ŒµŒæ ŒøŒªŒøŒ∫ŒªŒÆœÅŒøœÖ Œ±œÄœå Œ±œÄœåœÉœÑŒ±œÉŒ∑ Œ∫Œ±Œπ ŒºœÄŒøœÅŒµŒØ ŒΩŒ± œÉœÖŒºŒºŒµœÑŒ≠œáŒµŒπ Œ∫Œ¨Œ∏Œµ ŒµŒºœÄŒªŒµŒ∫œåŒºŒµŒΩŒøœÇ œÉœÑŒ∑ ŒÆ/Œ∫Œ±Œπ ŒµŒΩŒ¥ŒπŒ±œÜŒµœÅœåŒºŒµŒΩŒøœÇ Œ≥ŒπŒ± œÑŒ∑ Œ¥ŒπŒ¥Œ±œÉŒ∫Œ±ŒªŒØŒ± œÑŒ∑œÇ ŒïŒªŒªŒ∑ŒΩŒπŒ∫ŒÆœÇ œâœÇ Œ¥ŒµœçœÑŒµœÅŒ∑œÇ/ŒæŒ≠ŒΩŒ∑œÇ Œ≥ŒªœéœÉœÉŒ±œÇ œÉœÑŒ∑ŒΩ ŒïŒªŒªŒ¨Œ¥Œ± Œ∫Œ±Œπ œÉœÑŒø ŒµŒæœâœÑŒµœÅŒπŒ∫œå, Œ±œÅŒ∫ŒµŒØ ŒΩŒ± ŒµŒØŒΩŒ±Œπ Œ±œÄœåœÜŒøŒπœÑŒøœÇ ŒµŒªŒªŒ∑ŒΩŒπŒ∫ŒÆœÇ œÜŒπŒªŒøŒªŒøŒ≥ŒØŒ±œÇ, ŒæŒ≠ŒΩœâŒΩ œÜŒπŒªŒøŒªŒøŒ≥ŒπœéŒΩ, œÄŒ±ŒπŒ¥Œ±Œ≥œâŒ≥ŒπŒ∫œéŒΩ œÑŒºŒ∑ŒºŒ¨œÑœâŒΩ, Œ∏ŒµŒøŒªŒøŒ≥ŒπŒ∫œéŒΩ œÉœáŒøŒªœéŒΩ ŒÆ Œ¨ŒªŒªœâŒΩ œÄŒ±ŒΩŒµœÄŒπœÉœÑŒ∑ŒºŒπŒ±Œ∫œéŒΩ œÑŒºŒ∑ŒºŒ¨œÑœâŒΩ ŒµŒªŒªŒ∑ŒΩŒπŒ∫œéŒΩ ŒÆ ŒπœÉœåœÑŒπŒºœâŒΩ ŒæŒ≠ŒΩœâŒΩ œÄŒ±ŒΩŒµœÄŒπœÉœÑŒ∑ŒºŒØœâŒΩ. Œ•œÄœå œåœÅŒøœÖœÇ Œ≥ŒØŒΩŒøŒΩœÑŒ±Œπ Œ¥ŒµŒ∫œÑŒøŒØ œÖœÄŒøœàŒÆœÜŒπŒøŒπ œÄŒøœÖ Œ¥ŒµŒΩ Œ≠œáŒøœÖŒΩ ŒøŒªŒøŒ∫ŒªŒ∑œÅœéœÉŒµŒπ œÉœÄŒøœÖŒ¥Œ≠œÇ œÑœÅŒπœÑŒøŒ≤Œ¨Œ∏ŒºŒπŒ±œÇ ŒµŒ∫œÄŒ±ŒØŒ¥ŒµœÖœÉŒ∑œÇ.",
        };
        let tokens = match lng {
            Lang::Zho => vec![
                PositionalToken {
                    source: uws,
                    offset: 0,
                    length: 3,
                    token: Token::Word(Word::Word("Áæé".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 3,
                    length: 3,
                    token: Token::Word(Word::Word("ÂõΩ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 6,
                    length: 3,
                    token: Token::Word(Word::Word("Áîµ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 9,
                    length: 3,
                    token: Token::Word(Word::Word("ËßÜ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 12,
                    length: 3,
                    token: Token::Word(Word::Word("Ëøû".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 15,
                    length: 3,
                    token: Token::Word(Word::Word("Áª≠".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 18,
                    length: 3,
                    token: Token::Word(Word::Word("Ââß".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 21,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„Ää')),
                },
                PositionalToken {
                    source: uws,
                    offset: 24,
                    length: 3,
                    token: Token::Word(Word::Word("Ë∂Ö".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 27,
                    length: 3,
                    token: Token::Word(Word::Word("‰∫∫".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 30,
                    length: 3,
                    token: Token::Word(Word::Word("Ââç".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 33,
                    length: 3,
                    token: Token::Word(Word::Word("‰º†".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 36,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„Äã')),
                },
                PositionalToken {
                    source: uws,
                    offset: 39,
                    length: 3,
                    token: Token::Word(Word::Word("ÁöÑ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 42,
                    length: 3,
                    token: Token::Word(Word::Word("Á¨¨".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 45,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏Ä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 48,
                    length: 3,
                    token: Token::Word(Word::Word("ÈõÜ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 51,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„Ää')),
                },
                PositionalToken {
                    source: uws,
                    offset: 54,
                    length: 3,
                    token: Token::Word(Word::Word("ËØï".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 57,
                    length: 3,
                    token: Token::Word(Word::Word("Êí≠".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 60,
                    length: 3,
                    token: Token::Word(Word::Word("ÈõÜ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 63,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„Äã')),
                },
                PositionalToken {
                    source: uws,
                    offset: 66,
                    length: 3,
                    token: Token::Word(Word::Word("‰∫é".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 69,
                    length: 4,
                    token: Token::Word(Word::Number(Number::Integer(2001))),
                },
                PositionalToken {
                    source: uws,
                    offset: 73,
                    length: 3,
                    token: Token::Word(Word::Word("Âπ¥".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 76,
                    length: 2,
                    token: Token::Word(Word::Number(Number::Integer(10))),
                },
                PositionalToken {
                    source: uws,
                    offset: 78,
                    length: 3,
                    token: Token::Word(Word::Word("Êúà".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 81,
                    length: 2,
                    token: Token::Word(Word::Number(Number::Integer(16))),
                },
                PositionalToken {
                    source: uws,
                    offset: 83,
                    length: 3,
                    token: Token::Word(Word::Word("Êó•".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 86,
                    length: 3,
                    token: Token::Word(Word::Word("Âú®".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 89,
                    length: 3,
                    token: Token::Word(Word::Word("Èõª".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 92,
                    length: 3,
                    token: Token::Word(Word::Word("Ë¶ñ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 95,
                    length: 3,
                    token: Token::Word(Word::Word("Á∂≤".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 98,
                    length: 3,
                    token: Token::Word(Word::Word("È¶ñ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 101,
                    length: 3,
                    token: Token::Word(Word::Word("Êí≠".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 104,
                    length: 3,
                    token: Token::Special(Special::Punctuation('Ôºå')),
                },
                PositionalToken {
                    source: uws,
                    offset: 107,
                    length: 3,
                    token: Token::Word(Word::Word("Ââß".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 110,
                    length: 3,
                    token: Token::Word(Word::Word("ÈõÜ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 113,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏ª".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 116,
                    length: 3,
                    token: Token::Word(Word::Word("Âàõ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 119,
                    length: 3,
                    token: Token::Word(Word::Word("‰∫∫".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 122,
                    length: 3,
                    token: Token::Word(Word::Word("Èòø".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 125,
                    length: 3,
                    token: Token::Word(Word::Word("Â∞î".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 128,
                    length: 3,
                    token: Token::Word(Word::Word("Âºó".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 131,
                    length: 3,
                    token: Token::Word(Word::Word("Èõ∑".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 134,
                    length: 3,
                    token: Token::Word(Word::Word("Âæ∑".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 137,
                    length: 2,
                    token: Token::Special(Special::Punctuation('¬∑')),
                },
                PositionalToken {
                    source: uws,
                    offset: 139,
                    length: 3,
                    token: Token::Word(Word::Word("È´ò".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 142,
                    length: 3,
                    token: Token::Word(Word::Word("Â§´".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 145,
                    length: 3,
                    token: Token::Word(Word::Word("Âíå".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 148,
                    length: 3,
                    token: Token::Word(Word::Word("Ëøà".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 151,
                    length: 3,
                    token: Token::Word(Word::Word("Â∞î".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 154,
                    length: 3,
                    token: Token::Word(Word::Word("ÊñØ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 157,
                    length: 2,
                    token: Token::Special(Special::Punctuation('¬∑')),
                },
                PositionalToken {
                    source: uws,
                    offset: 159,
                    length: 3,
                    token: Token::Word(Word::Word("Á±≥".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 162,
                    length: 3,
                    token: Token::Word(Word::Word("Âãí".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 165,
                    length: 3,
                    token: Token::Word(Word::Word("Á∑®".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 168,
                    length: 3,
                    token: Token::Word(Word::Word("Âäá".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 171,
                    length: 3,
                    token: Token::Special(Special::Punctuation('Ôºå')),
                },
                PositionalToken {
                    source: uws,
                    offset: 174,
                    length: 3,
                    token: Token::Word(Word::Word("Â§ß".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 177,
                    length: 3,
                    token: Token::Word(Word::Word("Âç´".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 180,
                    length: 2,
                    token: Token::Special(Special::Punctuation('¬∑')),
                },
                PositionalToken {
                    source: uws,
                    offset: 182,
                    length: 3,
                    token: Token::Word(Word::Word("Âä™".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 185,
                    length: 3,
                    token: Token::Word(Word::Word("Áâπ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 188,
                    length: 3,
                    token: Token::Word(Word::Word("Â∞î".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 191,
                    length: 3,
                    token: Token::Word(Word::Word("Êâß".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 194,
                    length: 3,
                    token: Token::Word(Word::Word("ÂØº".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 197,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„ÄÇ')),
                },
                PositionalToken {
                    source: uws,
                    offset: 200,
                    length: 3,
                    token: Token::Word(Word::Word("Ëøô".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 203,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏Ä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 206,
                    length: 3,
                    token: Token::Word(Word::Word("ËØï".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 209,
                    length: 3,
                    token: Token::Word(Word::Word("Êí≠".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 212,
                    length: 3,
                    token: Token::Word(Word::Word("È¶ñ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 215,
                    length: 3,
                    token: Token::Word(Word::Word("Ê¨°".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 218,
                    length: 3,
                    token: Token::Word(Word::Word("Âêë".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 221,
                    length: 3,
                    token: Token::Word(Word::Word("ËßÇ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 224,
                    length: 3,
                    token: Token::Word(Word::Word("‰ºó".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 227,
                    length: 3,
                    token: Token::Word(Word::Word("Âºï".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 230,
                    length: 3,
                    token: Token::Word(Word::Word("Ëçê".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 233,
                    length: 3,
                    token: Token::Word(Word::Word("‰∫Ü".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 236,
                    length: 3,
                    token: Token::Word(Word::Word("ÂÖã".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 239,
                    length: 3,
                    token: Token::Word(Word::Word("Êãâ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 242,
                    length: 3,
                    token: Token::Word(Word::Word("ÂÖã".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 245,
                    length: 2,
                    token: Token::Special(Special::Punctuation('¬∑')),
                },
                PositionalToken {
                    source: uws,
                    offset: 247,
                    length: 3,
                    token: Token::Word(Word::Word("ËÇØ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 250,
                    length: 3,
                    token: Token::Word(Word::Word("Áâπ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 253,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏Ä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 256,
                    length: 3,
                    token: Token::Word(Word::Word("Ëßí".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 259,
                    length: 3,
                    token: Token::Special(Special::Punctuation('Ôºå')),
                },
                PositionalToken {
                    source: uws,
                    offset: 262,
                    length: 3,
                    token: Token::Word(Word::Word("‰ªñ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 265,
                    length: 3,
                    token: Token::Word(Word::Word("ÊòØ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 268,
                    length: 3,
                    token: Token::Word(Word::Word("‰Ωç".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 271,
                    length: 3,
                    token: Token::Word(Word::Word("Êã•".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 274,
                    length: 3,
                    token: Token::Word(Word::Word("Êúâ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 277,
                    length: 3,
                    token: Token::Word(Word::Word("Ë∂Ö".to_string())),
                },
            ],
            Lang::Jpn => vec![
                PositionalToken {
                    source: uws,
                    offset: 0,
                    length: 3,
                    token: Token::Word(Word::Word("ÁÜä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 3,
                    length: 3,
                    token: Token::Word(Word::Word("Èáé".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 6,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏â".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 9,
                    length: 3,
                    token: Token::Word(Word::Word("Â±±".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 12,
                    length: 3,
                    token: Token::Word(Word::Word("Êú¨".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 15,
                    length: 3,
                    token: Token::Word(Word::Word("È°ò".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 18,
                    length: 3,
                    token: Token::Word(Word::Word("ÊâÄ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 21,
                    length: 3,
                    token: Token::Word(Word::Word("„ÅØ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 24,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„ÄÅ')),
                },
                PositionalToken {
                    source: uws,
                    offset: 27,
                    length: 2,
                    token: Token::Word(Word::Number(Number::Integer(15))),
                },
                PositionalToken {
                    source: uws,
                    offset: 29,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏ñ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 32,
                    length: 3,
                    token: Token::Word(Word::Word("Á¥Ä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 35,
                    length: 3,
                    token: Token::Word(Word::Word("Êú´".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 38,
                    length: 3,
                    token: Token::Word(Word::Word("‰ª•".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 41,
                    length: 3,
                    token: Token::Word(Word::Word("Èôç".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 44,
                    length: 3,
                    token: Token::Word(Word::Word("„Å´".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 47,
                    length: 3,
                    token: Token::Word(Word::Word("„Åä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 50,
                    length: 3,
                    token: Token::Word(Word::Word("„Åë".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 53,
                    length: 3,
                    token: Token::Word(Word::Word("„Çã".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 56,
                    length: 3,
                    token: Token::Word(Word::Word("ÁÜä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 59,
                    length: 3,
                    token: Token::Word(Word::Word("Èáé".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 62,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏â".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 65,
                    length: 3,
                    token: Token::Word(Word::Word("Â±±".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 68,
                    length: 3,
                    token: Token::Special(Special::Punctuation('Ôºà')),
                },
                PositionalToken {
                    source: uws,
                    offset: 71,
                    length: 3,
                    token: Token::Word(Word::Word("ÁÜä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 74,
                    length: 3,
                    token: Token::Word(Word::Word("Èáé".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 77,
                    length: 3,
                    token: Token::Word(Word::Word("Êú¨".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 80,
                    length: 3,
                    token: Token::Word(Word::Word("ÂÆÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 83,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„ÄÅ')),
                },
                PositionalToken {
                    source: uws,
                    offset: 86,
                    length: 3,
                    token: Token::Word(Word::Word("ÁÜä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 89,
                    length: 3,
                    token: Token::Word(Word::Word("Èáé".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 92,
                    length: 3,
                    token: Token::Word(Word::Word("Êñ∞".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 95,
                    length: 3,
                    token: Token::Word(Word::Word("ÂÆÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 98,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„ÄÅ')),
                },
                PositionalToken {
                    source: uws,
                    offset: 101,
                    length: 3,
                    token: Token::Word(Word::Word("ÁÜä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 104,
                    length: 3,
                    token: Token::Word(Word::Word("Èáé".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 107,
                    length: 3,
                    token: Token::Word(Word::Word("ÈÇ£".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 110,
                    length: 3,
                    token: Token::Word(Word::Word("Êô∫".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 113,
                    length: 3,
                    token: Token::Special(Special::Punctuation('Ôºâ')),
                },
                PositionalToken {
                    source: uws,
                    offset: 116,
                    length: 3,
                    token: Token::Word(Word::Word("„ÅÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 119,
                    length: 3,
                    token: Token::Word(Word::Word("ÈÄ†".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 122,
                    length: 3,
                    token: Token::Word(Word::Word("Âñ∂".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 125,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„Éª')),
                },
                PositionalToken {
                    source: uws,
                    offset: 128,
                    length: 3,
                    token: Token::Word(Word::Word("‰øÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 131,
                    length: 3,
                    token: Token::Word(Word::Word("ÈÄ†".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 134,
                    length: 3,
                    token: Token::Word(Word::Word("„ÅÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 137,
                    length: 3,
                    token: Token::Word(Word::Word("„Åü".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 140,
                    length: 3,
                    token: Token::Word(Word::Word("„ÇÅ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 143,
                    length: 3,
                    token: Token::Word(Word::Word("„ÅÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 146,
                    length: 3,
                    token: Token::Word(Word::Word("Âãß".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 149,
                    length: 3,
                    token: Token::Word(Word::Word("ÈÄ≤".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 152,
                    length: 3,
                    token: Token::Word(Word::Word("„Çí".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 155,
                    length: 3,
                    token: Token::Word(Word::Word("ÊãÖ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 158,
                    length: 3,
                    token: Token::Word(Word::Word("„Å£".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 161,
                    length: 3,
                    token: Token::Word(Word::Word("„Åü".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 164,
                    length: 3,
                    token: Token::Word(Word::Word("ÁµÑ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 167,
                    length: 3,
                    token: Token::Word(Word::Word("Áπî".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 170,
                    length: 3,
                    token: Token::Word(Word::Word("„ÅÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 173,
                    length: 3,
                    token: Token::Word(Word::Word("Á∑è".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 176,
                    length: 3,
                    token: Token::Word(Word::Word("Áß∞".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 179,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„ÄÇ')),
                },
                PositionalToken {
                    source: uws,
                    offset: 182,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 183,
                    length: 3,
                    token: Token::Word(Word::Word("ÁÜä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 186,
                    length: 3,
                    token: Token::Word(Word::Word("Èáé".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 189,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏â".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 192,
                    length: 3,
                    token: Token::Word(Word::Word("Â±±".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 195,
                    length: 3,
                    token: Token::Word(Word::Word("„Çí".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 198,
                    length: 3,
                    token: Token::Word(Word::Word("Âê´".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 201,
                    length: 3,
                    token: Token::Word(Word::Word("„ÇÅ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 204,
                    length: 3,
                    token: Token::Word(Word::Word("„Å¶".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 207,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„ÄÅ')),
                },
                PositionalToken {
                    source: uws,
                    offset: 210,
                    length: 3,
                    token: Token::Word(Word::Word("Êó•".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 213,
                    length: 3,
                    token: Token::Word(Word::Word("Êú¨".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 216,
                    length: 3,
                    token: Token::Word(Word::Word("„Å´".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 219,
                    length: 3,
                    token: Token::Word(Word::Word("„Åä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 222,
                    length: 3,
                    token: Token::Word(Word::Word("„Åë".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 225,
                    length: 3,
                    token: Token::Word(Word::Word("„Çã".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 228,
                    length: 3,
                    token: Token::Word(Word::Word("Âè§".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 231,
                    length: 3,
                    token: Token::Word(Word::Word("‰ª£".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 234,
                    length: 3,
                    token: Token::Word(Word::Word("„Åã".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 237,
                    length: 3,
                    token: Token::Word(Word::Word("„Çâ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 240,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏≠".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 243,
                    length: 3,
                    token: Token::Word(Word::Word("‰∏ñ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 246,
                    length: 3,
                    token: Token::Word(Word::Word("Ââç".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 249,
                    length: 3,
                    token: Token::Word(Word::Word("Âçä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 252,
                    length: 3,
                    token: Token::Word(Word::Word("„Å´".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 255,
                    length: 3,
                    token: Token::Word(Word::Word("„Åã".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 258,
                    length: 3,
                    token: Token::Word(Word::Word("„Åë".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 261,
                    length: 3,
                    token: Token::Word(Word::Word("„Å¶".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 264,
                    length: 3,
                    token: Token::Word(Word::Word("„ÅÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 267,
                    length: 3,
                    token: Token::Word(Word::Word("ÂØ∫".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 270,
                    length: 3,
                    token: Token::Word(Word::Word("Á§æ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 273,
                    length: 3,
                    token: Token::Word(Word::Word("„ÅÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 276,
                    length: 3,
                    token: Token::Word(Word::Word("ÈÄ†".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 279,
                    length: 3,
                    token: Token::Word(Word::Word("Âñ∂".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 282,
                    length: 3,
                    token: Token::Word(Word::Word("„ÅØ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 285,
                    length: 3,
                    token: Token::Special(Special::Punctuation('„ÄÅ')),
                },
                PositionalToken {
                    source: uws,
                    offset: 288,
                    length: 3,
                    token: Token::Word(Word::Word("ÂØ∫".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 291,
                    length: 3,
                    token: Token::Word(Word::Word("Á§æ".to_string())),
                },
            ],
            Lang::Kor => vec![
                PositionalToken {
                    source: uws,
                    offset: 0,
                    length: 21,
                    token: Token::Word(Word::Word("ÌîåÎ†àÏù¥Ïä§ÌÖåÏù¥ÏÖò".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 21,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 22,
                    length: 3,
                    token: Token::Word(Word::Word("ÏùÄ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 25,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 26,
                    length: 6,
                    token: Token::Word(Word::Word("ÏÜåÎãà".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 32,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 33,
                    length: 9,
                    token: Token::Word(Word::Word("Ïª¥Ìì®ÌÑ∞".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 42,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 43,
                    length: 21,
                    token: Token::Word(Word::Word("ÏóîÌÑ∞ÌÖåÏù∏Î®ºÌä∏Í∞Ä".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 64,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 65,
                    length: 9,
                    token: Token::Word(Word::Word("Í∞úÎ∞úÌïú".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 74,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 75,
                    length: 3,
                    token: Token::Word(Word::Word("ÏÑ∏".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 78,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 79,
                    length: 6,
                    token: Token::Word(Word::Word("Î≤àÏß∏".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 85,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 86,
                    length: 9,
                    token: Token::Word(Word::Word("Í∞ÄÏ†ïÏö©".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 95,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 96,
                    length: 15,
                    token: Token::Word(Word::Word("Í≤åÏûÑÍ∏∞Ïù¥Îã§".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 111,
                    length: 1,
                    token: Token::Special(Special::Punctuation('.')),
                },
                PositionalToken {
                    source: uws,
                    offset: 112,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 113,
                    length: 24,
                    token: Token::Word(Word::Word("ÎßàÏù¥ÌÅ¨Î°úÏÜåÌîÑÌä∏Ïùò".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 137,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 138,
                    length: 12,
                    token: Token::Word(Word::Word("ÏóëÏä§Î∞ïÏä§".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 150,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 151,
                    length: 3,
                    token: Token::Word(Word::Number(Number::Integer(360))),
                },
                PositionalToken {
                    source: uws,
                    offset: 154,
                    length: 1,
                    token: Token::Special(Special::Punctuation(',')),
                },
                PositionalToken {
                    source: uws,
                    offset: 155,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 156,
                    length: 12,
                    token: Token::Word(Word::Word("ÎãåÌÖêÎèÑÏùò".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 168,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 169,
                    length: 6,
                    token: Token::Word(Word::Word("WiiÏôÄ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 175,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 176,
                    length: 12,
                    token: Token::Word(Word::Word("Í≤ΩÏüÅÌïòÍ≥†".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 188,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 189,
                    length: 6,
                    token: Token::Word(Word::Word("ÏûàÎã§".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 195,
                    length: 1,
                    token: Token::Special(Special::Punctuation('.')),
                },
                PositionalToken {
                    source: uws,
                    offset: 196,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 197,
                    length: 6,
                    token: Token::Word(Word::Word("Ïù¥Ï†Ñ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 203,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 204,
                    length: 12,
                    token: Token::Word(Word::Word("Ï†úÌíàÏóêÏÑú".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 216,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 217,
                    length: 9,
                    token: Token::Word(Word::Word("Ïò®ÎùºÏù∏".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 226,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 227,
                    length: 9,
                    token: Token::Word(Word::Word("ÌîåÎ†àÏù¥".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 236,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 237,
                    length: 3,
                    token: Token::Word(Word::Word("Í∏∞".to_string())),
                },
            ],
            Lang::Ara => vec![
                PositionalToken {
                    source: uws,
                    offset: 0,
                    length: 14,
                    token: Token::Word(Word::Word("ŸÑÿ¥⁄©ÿ±⁄©ÿ¥€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 14,
                    length: 3,
                    token: Token::Unicode(Unicode::Formatter(Formatter::Char('\u{200c}'))),
                },
                PositionalToken {
                    source: uws,
                    offset: 17,
                    length: 6,
                    token: Token::Word(Word::Word("Ÿáÿß€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 23,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 24,
                    length: 6,
                    token: Token::Word(Word::Word("ÿ±Ÿàÿ≥".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 30,
                    length: 3,
                    token: Token::Unicode(Unicode::Formatter(Formatter::Char('\u{200c}'))),
                },
                PositionalToken {
                    source: uws,
                    offset: 33,
                    length: 6,
                    token: Token::Word(Word::Word("Ÿáÿß€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 39,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 40,
                    length: 12,
                    token: Token::Word(Word::Word("Ÿàÿßÿ±ŸÜ⁄Ø€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 52,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 53,
                    length: 4,
                    token: Token::Word(Word::Word("ÿ®Ÿá".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 57,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 58,
                    length: 10,
                    token: Token::Word(Word::Word("ÿØÿ±€åÿß€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 68,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 69,
                    length: 6,
                    token: Token::Word(Word::Word("ÿÆÿ≤ÿ±".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 75,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 76,
                    length: 12,
                    token: Token::Word(Word::Word("ŸÖÿ¨ŸÖŸàÿπŸá".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 88,
                    length: 3,
                    token: Token::Unicode(Unicode::Formatter(Formatter::Char('\u{200c}'))),
                },
                PositionalToken {
                    source: uws,
                    offset: 91,
                    length: 4,
                    token: Token::Word(Word::Word("ÿß€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 95,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 96,
                    length: 4,
                    token: Token::Word(Word::Word("ÿßÿ≤".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 100,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 101,
                    length: 10,
                    token: Token::Word(Word::Word("ÿ≠ŸÖŸÑÿßÿ™".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 111,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 112,
                    length: 10,
                    token: Token::Word(Word::Word("ŸÜÿ∏ÿßŸÖ€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 122,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 123,
                    length: 4,
                    token: Token::Word(Word::Word("ÿØÿ±".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 127,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 128,
                    length: 6,
                    token: Token::Word(Word::Word("ÿ®€åŸÜ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 134,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 135,
                    length: 6,
                    token: Token::Word(Word::Word("ÿ≥ÿßŸÑ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 141,
                    length: 3,
                    token: Token::Unicode(Unicode::Formatter(Formatter::Char('\u{200c}'))),
                },
                PositionalToken {
                    source: uws,
                    offset: 144,
                    length: 6,
                    token: Token::Word(Word::Word("Ÿáÿß€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 150,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 151,
                    length: 6,
                    token: Token::Word(Word::StrangeWord("€∏€∂€¥".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 157,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 158,
                    length: 4,
                    token: Token::Word(Word::Word("ÿ™ÿß".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 162,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 163,
                    length: 8,
                    token: Token::Word(Word::StrangeWord("€±€∞€¥€±".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 171,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 172,
                    length: 12,
                    token: Token::Word(Word::Word("ŸÖ€åŸÑÿßÿØ€å".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 184,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 185,
                    length: 2,
                    token: Token::Word(Word::Word("ÿ®".to_string())),
                },
            ],
            Lang::Ell => vec![
                PositionalToken {
                    source: uws,
                    offset: 0,
                    length: 4,
                    token: Token::Word(Word::Word("Œ§Œø".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 4,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 5,
                    length: 18,
                    token: Token::Word(Word::Word("Œ†œÅœåŒ≥œÅŒ±ŒºŒºŒ±".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 23,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 24,
                    length: 22,
                    token: Token::Word(Word::Word("œÖŒªŒøœÄŒøŒπŒµŒØœÑŒ±Œπ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 46,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 47,
                    length: 4,
                    token: Token::Word(Word::Word("ŒµŒæ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 51,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 52,
                    length: 18,
                    token: Token::Word(Word::Word("ŒøŒªŒøŒ∫ŒªŒÆœÅŒøœÖ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 70,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 71,
                    length: 6,
                    token: Token::Word(Word::Word("Œ±œÄœå".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 77,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 78,
                    length: 16,
                    token: Token::Word(Word::Word("Œ±œÄœåœÉœÑŒ±œÉŒ∑".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 94,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 95,
                    length: 6,
                    token: Token::Word(Word::Word("Œ∫Œ±Œπ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 101,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 102,
                    length: 12,
                    token: Token::Word(Word::Word("ŒºœÄŒøœÅŒµŒØ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 114,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 115,
                    length: 4,
                    token: Token::Word(Word::Word("ŒΩŒ±".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 119,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 120,
                    length: 20,
                    token: Token::Word(Word::Word("œÉœÖŒºŒºŒµœÑŒ≠œáŒµŒπ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 140,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 141,
                    length: 8,
                    token: Token::Word(Word::Word("Œ∫Œ¨Œ∏Œµ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 149,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 150,
                    length: 24,
                    token: Token::Word(Word::Word("ŒµŒºœÄŒªŒµŒ∫œåŒºŒµŒΩŒøœÇ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 174,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 175,
                    length: 6,
                    token: Token::Word(Word::Word("œÉœÑŒ∑".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 181,
                    length: 1,
                    token: Token::Special(Special::Separator(Separator::Space)),
                },
                PositionalToken {
                    source: uws,
                    offset: 182,
                    length: 2,
                    token: Token::Word(Word::Word("ŒÆ".to_string())),
                },
                PositionalToken {
                    source: uws,
                    offset: 184,
                    length: 1,
                    token: Token::Special(Special::Punctuation('/')),
                },
            ],
        };
        (
            uws.chars()
                .take(100)
                .fold(String::new(), |acc, c| acc + &format!("{}", c)),
            tokens,
        )
    }
}
